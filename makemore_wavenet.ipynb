{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare"
      ],
      "metadata": {
        "id": "NvdOyP1BFJNR"
      },
      "id": "NvdOyP1BFJNR"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/romenlaw/NaiveNeuralNetwork/blob/main/names.txt?raw=True\" -O names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTe65882k-zj",
        "outputId": "9568cfbe-befa-4b53-f8ef-f111f3b01147"
      },
      "id": "aTe65882k-zj",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-28 04:58:00--  https://github.com/romenlaw/NaiveNeuralNetwork/blob/main/names.txt?raw=True\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/romenlaw/NaiveNeuralNetwork/raw/main/names.txt [following]\n",
            "--2024-08-28 04:58:00--  https://github.com/romenlaw/NaiveNeuralNetwork/raw/main/names.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/romenlaw/NaiveNeuralNetwork/main/names.txt [following]\n",
            "--2024-08-28 04:58:01--  https://raw.githubusercontent.com/romenlaw/NaiveNeuralNetwork/main/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-08-28 04:58:01 (4.38 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "11fMpYyJnSe1"
      },
      "id": "11fMpYyJnSe1",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "len(words), max([len(w) for w in words]), words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQx5qdlxnxdz",
        "outputId": "8a690cc8-2e84-4f01-e294-45351fbb6eca"
      },
      "id": "OQx5qdlxnxdz",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32033,\n",
              " 15,\n",
              " ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia'])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(list(set(''.join(words))))\n",
        "vocab.insert(0, '.')\n",
        "vocab_size = len(vocab)\n",
        "itos={i:s for i, s in zip(range(vocab_size), vocab)}\n",
        "stoi={s:i for i, s in zip(range(vocab_size), vocab)}"
      ],
      "metadata": {
        "id": "3DZ2MKTbn9wr"
      },
      "id": "3DZ2MKTbn9wr",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build datasets: 80% training, 10% validation, 10% testing\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words) # shuffle is in-place\n",
        "\n",
        "\n",
        "block_size=3\n",
        "X, Y = [], []\n",
        "context = []\n",
        "for w in words:\n",
        "  context = [0] * block_size # context contains indices\n",
        "  for c in (w + '.'):\n",
        "    ix = stoi[c]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    if c=='.':\n",
        "      break\n",
        "    context = context[1:] + [ix]\n",
        "\n",
        "n1 = int(len(X)*.8)\n",
        "n2 = int(len(X)*.9)\n",
        "X_train = torch.tensor(X[:n1])\n",
        "Y_train = torch.tensor(Y[:n1])\n",
        "X_val = torch.tensor(X[n1:n2])\n",
        "Y_val = torch.tensor(Y[n1:n2])\n",
        "X_test = torch.tensor(X[n2:])\n",
        "Y_test = torch.tensor(Y[n2:])\n",
        "\n",
        "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape, X_test.shape, Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdYLaCVXp3Hz",
        "outputId": "3996f17f-beed-4f3a-89a3-7ad1a9b6e5c3"
      },
      "id": "KdYLaCVXp3Hz",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([182516, 3]),\n",
              " torch.Size([182516]),\n",
              " torch.Size([22815, 3]),\n",
              " torch.Size([22815]),\n",
              " torch.Size([22815, 3]),\n",
              " torch.Size([22815]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val[:5], Y_val[:5]"
      ],
      "metadata": {
        "id": "2TB4O_1_84D4",
        "outputId": "7822186e-bbd3-4d00-a2fc-89ae58715721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2TB4O_1_84D4",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  5, 13],\n",
              "         [ 5, 13, 13],\n",
              "         [13, 13,  1],\n",
              "         [13,  1, 12],\n",
              "         [ 1, 12,  9]]),\n",
              " tensor([13,  1, 12,  9,  5]))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "oiS-aoHoFNo7"
      },
      "id": "oiS-aoHoFNo7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## classes"
      ],
      "metadata": {
        "id": "dGFcxjwyOQCD"
      },
      "id": "dGFcxjwyOQCD"
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "  def __init__(self, fan_in, fan_out, bias=True):\n",
        "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5\n",
        "    self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.out = x @ self.weight\n",
        "    if self.bias is not None:\n",
        "      self.out += self.bias\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "class BatchNorm1d:\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps=eps\n",
        "    self.momentum = momentum\n",
        "    self.training = True\n",
        "\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "    self.running_mean = torch.zeros(dim)\n",
        "    self.running_var = torch.ones(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    if self.training:\n",
        "      xmean = x.mean(dim=0, keepdim=True)\n",
        "      xvar = x.var(dim=0, keepdim=True)\n",
        "      with torch.no_grad():\n",
        "        self.running_mean = (1-self.momentum)*self.running_mean + self.momentum*xmean\n",
        "        self.running_var = (1-self.momentum)*self.running_var + self.momentum*xvar\n",
        "    else:\n",
        "      xmean = self.running_mean\n",
        "      xvar = self.running_var\n",
        "\n",
        "    x_hat = (x - xmean) / (xvar + self.eps)**0.5\n",
        "    self.out = self.gamma * x_hat + self.beta\n",
        "\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "class Tanh:\n",
        "  def __call__(self, x):\n",
        "    self.out = torch.tanh(x)\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return []"
      ],
      "metadata": {
        "id": "bUWE4oJ8HM80"
      },
      "id": "bUWE4oJ8HM80",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## initialisation"
      ],
      "metadata": {
        "id": "UciEFr6GOR4c"
      },
      "id": "UciEFr6GOR4c"
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "emb_dim = 10\n",
        "hidden_dim = 200\n",
        "\n",
        "C = torch.randn((vocab_size, emb_dim))\n",
        "layers = [\n",
        "    Linear(emb_dim*block_size, hidden_dim, bias=False), BatchNorm1d(hidden_dim), Tanh(),\n",
        "    Linear(hidden_dim, vocab_size) # output layer\n",
        "]\n",
        "with torch.no_grad():\n",
        "  layers[-1].weight *= 0.1 # make output layer less confident(ly wrong)\n",
        "\n",
        "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
        "for p in parameters:\n",
        "  p.requires_grad=True\n",
        "print(sum(p.nelement() for p in parameters))"
      ],
      "metadata": {
        "id": "MqPChrKsIlg0",
        "outputId": "332c52d6-8274-404b-c9c0-fef6a419d1b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MqPChrKsIlg0",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12097\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dim*block_size * hidden_dim + hidden_dim*2 + hidden_dim*vocab_size +vocab_size+ vocab_size * emb_dim"
      ],
      "metadata": {
        "id": "sYN-SXO6SxjU",
        "outputId": "8eadeeb1-b9e3-46c2-fc6b-1f89e0d406db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sYN-SXO6SxjU",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12097"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training"
      ],
      "metadata": {
        "id": "buAWT-KqWXVX"
      },
      "id": "buAWT-KqWXVX"
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps=200000\n",
        "batch_size=32\n",
        "lossi=[]\n",
        "\n",
        "for step in range(max_steps):\n",
        "  # create mini_batch\n",
        "  ix = torch.randint(0, X_train.shape[0], size=(batch_size,))\n",
        "  Xb, Yb = X_train[ix], Y_train[ix]\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xb]  # (batch_size, vocab_size, emb_dim)\n",
        "  x = emb.view(emb.shape[0], -1)  # (batch_size, vocab_size*emb_dim)\n",
        "  for layer in layers:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, Yb)\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad=None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if step<100000 else 0.01\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  if step % 10000 ==0:\n",
        "    print('%7d/%7d: %2.10f' % (step, max_steps, loss))\n",
        "  lossi.append(loss)\n",
        "print('%7d/%7d: %2.10f' % (step, max_steps, loss))"
      ],
      "metadata": {
        "id": "-aXTRRcKWZ3t",
        "outputId": "323a123c-c6f8-4f0d-dcc5-10921ce0cd5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-aXTRRcKWZ3t",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 3.3003702164\n",
            "  10000/ 200000: 2.1085405350\n",
            "  20000/ 200000: 2.3290817738\n",
            "  30000/ 200000: 1.6030472517\n",
            "  40000/ 200000: 2.4885463715\n",
            "  50000/ 200000: 2.0115578175\n",
            "  60000/ 200000: 2.2257134914\n",
            "  70000/ 200000: 2.1586527824\n",
            "  80000/ 200000: 2.0268161297\n",
            "  90000/ 200000: 2.1670222282\n",
            " 100000/ 200000: 2.2194030285\n",
            " 110000/ 200000: 2.1041414738\n",
            " 120000/ 200000: 1.8756295443\n",
            " 130000/ 200000: 2.0888373852\n",
            " 140000/ 200000: 2.3188447952\n",
            " 150000/ 200000: 2.2042424679\n",
            " 160000/ 200000: 2.3583600521\n",
            " 170000/ 200000: 2.3546292782\n",
            " 180000/ 200000: 1.9698082209\n",
            " 190000/ 200000: 2.0460581779\n",
            " 199999/ 200000: 1.9368194342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## validate"
      ],
      "metadata": {
        "id": "R6JTa0E4cEqa"
      },
      "id": "R6JTa0E4cEqa"
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in layers:\n",
        "  layer.training = False\n",
        "\n",
        "@torch.no_grad()\n",
        "def split_loss(s):\n",
        "  \"\"\"s is one of 'train', 'val', 'test'\n",
        "  \"\"\"\n",
        "  xs, ys = { 'train': (X_train, Y_train),\n",
        "          'val': (X_val, Y_val,),\n",
        "           'test': (X_test, Y_test)}[s]\n",
        "  # forward pass\n",
        "  emb = C[xs]\n",
        "  x = emb.view(emb.shape[0], -1)\n",
        "  for layer in layers:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, ys)\n",
        "  print(s, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "id": "sOwCcfuBcGTX",
        "outputId": "d594d57a-148c-4837-a9ad-b3e945a284c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sOwCcfuBcGTX",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.0648605823516846\n",
            "val 2.1072237491607666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers[1].running_mean.shape"
      ],
      "metadata": {
        "id": "WN6gFzY6e6M7",
        "outputId": "638c243d-94c4-433a-c538-4dc7d8eddc2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WN6gFzY6e6M7",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample"
      ],
      "metadata": {
        "id": "1CWWv1zkhIIW"
      },
      "id": "1CWWv1zkhIIW"
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for _ in range(20):\n",
        "    out=[]\n",
        "    context=[0]*block_size\n",
        "\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1, block_size, emb_dim)\n",
        "      x = emb.view(emb.shape[0], -1)\n",
        "      for layer in layers:\n",
        "        x = layer(x)\n",
        "      probs = F.softmax(x, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1)\n",
        "      context = context[1:]+[ix]\n",
        "      out.append(ix.item())\n",
        "      if ix==0:\n",
        "        break\n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "id": "TlEoCaH-hJiT",
        "outputId": "d87885d1-dbcf-471f-b49e-563298a7e0fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TlEoCaH-hJiT",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alyz.\n",
            "aris.\n",
            "tri.\n",
            "gere.\n",
            "sayah.\n",
            "ayvorie.\n",
            "rosson.\n",
            "emon.\n",
            "catine.\n",
            "aib.\n",
            "alitithira.\n",
            "liza.\n",
            "jemin.\n",
            "ana.\n",
            "alynna.\n",
            "jamaur.\n",
            "ben.\n",
            "quan.\n",
            "tori.\n",
            "makyia.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}