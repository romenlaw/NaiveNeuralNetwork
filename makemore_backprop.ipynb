{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romenlaw/NaiveNeuralNetwork/blob/main/makemore_backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4f4JG1gdKqj"
      },
      "source": [
        "#Makemore - backprop ninja"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare datasets"
      ],
      "metadata": {
        "id": "vTLLwG6T_Srt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/romenlaw/NaiveNeuralNetwork/main/names.txt"
      ],
      "metadata": {
        "id": "WnJ_g9N870O8",
        "outputId": "fc9a0541-f311-4d98-dfc0-8e51f8c32938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  222k  100  222k    0     0   713k      0 --:--:-- --:--:-- --:--:--  714k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "kI-rQ1qpCWoV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "len(words), max(len(w) for w in words), words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RRwKoRN_V0p",
        "outputId": "a7a761c5-32f9-4758-f728-7a0eeb0e543c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32033,\n",
              " 15,\n",
              " ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(list(set(''.join(words))))\n",
        "vocab.insert(0, '.')\n",
        "itos = { i:s for i,s in enumerate(vocab)}\n",
        "stoi = { s:i for i,s in enumerate(vocab)}\n",
        "vocab_size = len(vocab)  # 27"
      ],
      "metadata": {
        "id": "rWeh-qTNAOxO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3  # context size - 3 tokens\n",
        "\n",
        "def build_dataset(words):\n",
        "  \"\"\"returns torch tensors X, Y where\n",
        "  X is a list of n-grams indices covering the whole words list, where n=block_size\n",
        "  Y is a list of indices predicting each n-gram in X\n",
        "  \"\"\"\n",
        "  X, Y = [], []\n",
        "\n",
        "  #for w in words[:5]:\n",
        "  for w in words:\n",
        "    context = [0] * block_size # repeat '.' to fill block_size\n",
        "    for ch in w+'.':\n",
        "      ix = stoi[ch]\n",
        "      #print(' '.join([itos[i] for i in context]), '---->', itos[ix])\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix]\n",
        "\n",
        "  return torch.tensor(X), torch.tensor(Y)\n",
        "\n",
        "X, Y = build_dataset(words)\n",
        "#X[:32], Y[:32]\n",
        "\n",
        "# split the data into 3 sets\n",
        "# 80% for training set\n",
        "# 10% for validation/development\n",
        "# 10% for testing\n",
        "import random\n",
        "random.seed(42)\n",
        "n1 = int(len(words) * .8)\n",
        "n2 = int(len(words) * .9)\n",
        "random.shuffle(words) # shuffle is in-place\n",
        "X_train, Y_train = build_dataset(words[:n1])\n",
        "X_dev, Y_dev = build_dataset(words[n1:n2])\n",
        "X_test, Y_test = build_dataset(words[n2:])\n",
        "\n",
        "#len(words[n1:n2])\n",
        "(X_train.shape, Y_train.shape), (X_dev.shape, Y_dev.shape), (X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_wuMWU1BUFe",
        "outputId": "29de2c24-3412-4536-d682-a4998f152720"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((torch.Size([182625, 3]), torch.Size([182625])),\n",
              " (torch.Size([22655, 3]), torch.Size([22655])),\n",
              " (torch.Size([22866, 3]), torch.Size([22866])))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utilities"
      ],
      "metadata": {
        "id": "_Zrl2yoKDHSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utility to compare our manual gradients with pytorch gradients\n",
        "def cmp(s, dt, t):\n",
        "  \"\"\"Compares dt and t.grad to see if their values are equal or close\n",
        "  s - name of the parameter being compared, used in printing only\n",
        "  dt - tensor of manually calculated gradient\n",
        "  t - torch tensor\n",
        "  \"\"\"\n",
        "  ex = torch.all(dt==t.grad).item()\n",
        "  apx = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approx: {str(apx):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "x9d-letYDPF7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP\n",
        "In the parameter initialisation, we use non-standard values to see their effect; otherwise, for example, zeros can mask out any incorrect values."
      ],
      "metadata": {
        "id": "VAOQhg9HNNyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 10\n",
        "hidden_dim = 200\n",
        "\n",
        "g = torch.Generator().manual_seed(20240824)\n",
        "C = torch.randn((vocab_size, embed_dim),  generator=g)\n",
        "\n",
        "# hidden layer\n",
        "fan_in = embed_dim*block_size # we concat multiple C's to feed into hidden layer\n",
        "W1 = torch.randn((fan_in, hidden_dim), generator=g) * (5/3 / fan_in**0.5)\n",
        "b1 = torch.randn(hidden_dim,           generator=g) * 0.1 # experiment\n",
        "# output layer\n",
        "W2 = torch.randn((hidden_dim, vocab_size), generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,               generator=g) * 0.1 # experiment with non-zero\n",
        "\n",
        "# batch normalisation 1D layer placed after hidden layer, hence dim=hidden_dim\n",
        "bn_gamma = torch.randn((1, hidden_dim),    generator=g) * 0.1 + 1.0\n",
        "bn_bias = torch.randn((1, hidden_dim),     generator=g) * 0.1\n",
        "#bn_running_mean = torch.zeros((1, hidden_dim))\n",
        "#bn_running_std = torch.ones((1, hidden_dim))\n",
        "\n",
        "# the above are initialised with non-standard values to magnify any incorrect values\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bn_gamma, bn_bias]\n",
        "print('total params: ', sum([p.nelement() for p in parameters]))\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4EIrTkZNPpo",
        "outputId": "f1745f99-d054-4873-a9c7-89866ac02c0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total params:  12297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training - extended version\n",
        "We expand the forward pass into step by step calculations so that we can manually calculate the gradient step by step as well. For Cross Entropy loss function, see [pyTorch doco](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss).\n",
        "\n",
        "We don't call the loss.backward(). Instead, we will do it manually."
      ],
      "metadata": {
        "id": "T9c-gp2PM-Rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# understanding tensor.values, which only works on sparse tensor\n",
        "t = torch.randn((2,3))\n",
        "sparse_tensor = t.max(dim=1, keepdim=True)\n",
        "t, '-----------', sparse_tensor, '------------', sparse_tensor.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4UqInlQLqw4",
        "outputId": "02751176-ea13-4308-b5ee-7c21dc354821"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.1484,  2.3629,  0.1412],\n",
              "         [-1.2185, -1.6495,  0.1812]]),\n",
              " '-----------',\n",
              " torch.return_types.max(\n",
              " values=tensor([[2.3629],\n",
              "         [0.1812]]),\n",
              " indices=tensor([[1],\n",
              "         [2]])),\n",
              " '------------',\n",
              " tensor([[2.3629],\n",
              "         [0.1812]]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # construct mini-batch:\n",
        "  # generate a list of random indices, length of list if batch_size\n",
        "  ix = torch.randint(low=0, high=X_train.shape[0], size=(batch_size,), generator=g)\n",
        "  xs = X_train[ix]  # (batch_size, block_size)\n",
        "  ys = Y_train[ix]  # (batch_size)\n",
        "\n",
        "  ##################################\n",
        "  # forward pass (expanded version)\n",
        "  ##################################\n",
        "  # embedding ---------------------------\n",
        "  emb = C[xs] # (batch_size, block_size, hidden_dim)\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  # hidden layer ------------------------\n",
        "  h_prebn = embcat @ W1 + b1 # (batch_size, hidden_dim)\n",
        "  # BN layer (expended version) ----------------------------\n",
        "  #bn_mean = h_prebn.mean(dim=0, keepdim=True)\n",
        "  bn_mean = 1/batch_size*h_prebn.sum(dim=0, keepdim=True)\n",
        "  #bn_std = h_prebn.std(dim=0, keepdim=True)\n",
        "  bn_diff = (h_prebn - bn_mean)\n",
        "  bn_diff2 = bn_diff ** 2\n",
        "  bn_var = 1/(batch_size-1) * bn_diff2.sum(dim=0, keepdim=True) # Bessel's correction, divide by m-1 not m\n",
        "  bn_varinv = (bn_var + 1e-5)**-0.5  # 1/sqrt(var+eps)\n",
        "  x_hat = bn_diff * bn_varinv\n",
        "  h_preact = bn_gamma * x_hat + bn_bias\n",
        "  #with torch.no_grad():\n",
        "  #  bn_running_mean = 0.999 * bn_running_mean + 0.001 * bn_mean\n",
        "  #  bn_running_std = 0.999 * bn_running_std + 0.001 * bn_std\n",
        "  # Non-linearity ----------------------\n",
        "  h = torch.tanh(h_preact)  # (batch_size, hidden_dim)\n",
        "  # output layer -----------------------\n",
        "  logits = h @ W2 + b2 # (hidden_dim, vocab_size)\n",
        "  # loss function (extended version) ----------------------\n",
        "  #loss = F.cross_entropy(logits, ys)\n",
        "  logit_maxes = logits.max(dim=1, keepdim=True).values  # (hidden_dim, 1)\n",
        "  norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "  counts = norm_logits.exp()  # (batch_size, vocab_size)\n",
        "  counts_sum = counts.sum(dim=1, keepdim=True) # (batch_size, 1)\n",
        "  counts_sum_inv = counts_sum ** -1  # (batch_size, 1)\n",
        "  probs = counts * counts_sum_inv  # (batch_size, vocab_size)\n",
        "  logprobs = probs.log()   # (batch_size, vocab_size)\n",
        "  loss = -logprobs[range(batch_size), ys].mean()  # scalar\n",
        "\n",
        "  ################\n",
        "  # backward pass\n",
        "  ################\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  for t in [logprobs, probs, counts_sum_inv, counts_sum, counts,\n",
        "            norm_logits, logit_maxes, logits,\n",
        "            h, h_preact, x_hat, bn_varinv, bn_var, bn_diff2, bn_diff, bn_mean,\n",
        "            h_prebn, embcat, emb ]:\n",
        "    t.retain_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  ###############\n",
        "  # update\n",
        "  ###############\n",
        "  # lr = 0.1 if i<100000 else 0.01\n",
        "  # for p in parameters:\n",
        "  #   p.data += -lr * p.grad\n",
        "\n",
        "  # # tracking\n",
        "  # lossi.append(loss)\n",
        "  # if i%10000 == 0:\n",
        "  #   print('%6d/%7d %2.10f' % (i, max_steps, loss))\n",
        "\n",
        "  # if i>1000:\n",
        "  break\n",
        "print('%6d/%7d %2.10f' % (i, max_steps, loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOpGCG2TNAkI",
        "outputId": "e21c497c-8288-4e05-9b6b-65cd411a6e14"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0/ 200000 3.5082895756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb19DCBUFD3W",
        "outputId": "b7ef8501-09ab-4164-b256-77f133463170"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - backward pass of loss function"
      ],
      "metadata": {
        "id": "ry8Xbe9-DPNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dlogprobs\n",
        "logprobs is dimension (N, vocab_size) , where N = batch_size\n",
        "$$loss = -\\dfrac{1}{N}\\sum_{i=1}^{N}logprobs_{i, y_i}$$\n",
        "For the loss function, only elements at indices $[i, y_i]$ contribute to the loss. The rest are not used. Therefore, the unused elements have gradient 0.\n",
        "$$\\dfrac{\\delta loss}{\\delta logprobs}=\n",
        "\\begin{cases}\n",
        "-\\dfrac{1}{N} & \\quad \\text{at positions }{i},{y_i}\\\\\n",
        "0 & \\quad \\text{elsewhere}\n",
        "\\end{cases}\n",
        "$$"
      ],
      "metadata": {
        "id": "zcMTxreLHKO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(batch_size), ys] = -1/batch_size\n",
        "cmp('dlogprobs', dlogprobs, logprobs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek7Mmk4fO9kt",
        "outputId": "6568e813-230b-4c48-a739-71d2e708284e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogprobs       | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dprobs\n",
        "$$logprobs = \\ln(probs)$$\n",
        "$$\\dfrac{\\delta logprobs}{\\delta probs} = \\dfrac{1}{probs}\n",
        "$$"
      ],
      "metadata": {
        "id": "i_6hGt3IJduM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dprobs = 1/probs * dlogprobs\n",
        "cmp('dprobs', dprobs, probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZAWM-h4T_3y",
        "outputId": "d89e90f7-34e8-4f00-807e-f5ca6e407f4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dprobs          | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dcount_sum_inv\n",
        "\n",
        "$$probs = counts * \\text{counts_sum_inv}\n",
        "$$\n",
        "$$\\dfrac{\\delta probs}{\\delta \\text{counts_sum_inv}} = counts\n",
        "$$\n",
        "Note that the dimension of counts_sum_inv is (N, 1), so does its derivative."
      ],
      "metadata": {
        "id": "ocS5fuREeaw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum_inv = counts * dprobs\n",
        "dcounts_sum_inv = dcounts_sum_inv.sum(dim=1, keepdim=True)\n",
        "cmp('dcounts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUwrnaS7KURu",
        "outputId": "9fdc8047-be86-47ba-8cb2-ba67d556ef89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcounts_sum_inv | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dcounts_sum\n",
        "$$\\text{counts_sum_inv} = \\text{counts_sum}^{-1}\n",
        "$$\n",
        "$$\\dfrac{\\delta\\text{counts_sum_inv}}{\\delta\\text{counts_sum}} = -\\text{counts_sum}^{-2}\n",
        "$$"
      ],
      "metadata": {
        "id": "91_4MFMKh1aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum=-counts_sum**-2\n",
        "dcounts_sum *= dcounts_sum_inv\n",
        "cmp('dcounts_sum', dcounts_sum, counts_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2VR1zGJKonc",
        "outputId": "287b4224-3f17-46fc-e811-b175c6ecaa2f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcounts_sum     | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum[0], counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY4dWJRcvU8T",
        "outputId": "d3876d8b-649a-409c-e452-d2d3024fd83a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0040], grad_fn=<SelectBackward0>), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dcounts\n",
        "counts is used twice in the forward pass: once in counts_sum, another in probs.\n",
        "for counts_sum:\n",
        "$$\\text{counts_sum} = \\sum_{j=1}^{\\text{vocab_size}}counts_{i,j}\n",
        "$$\n",
        "$$\\dfrac{\\delta \\text{counts_sum}}{\\delta counts} = 1_{N, \\text{vocab_size}}\n",
        "$$\n",
        "Note that the 1 is same dimension as counts, i.e. (N, vocab_size)\n",
        "\n",
        "For probs:\n",
        "$$probs = counts * \\text{counts_sum_inv}\n",
        "$$\n",
        "$$\\dfrac{\\delta probs}{\\delta counts} = \\text{counts_sum_inv}\n",
        "$$"
      ],
      "metadata": {
        "id": "68bhFVV7i2n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts1 = torch.ones_like(counts) * dcounts_sum\n",
        "dcounts2 = counts_sum_inv * dprobs\n",
        "dcounts = dcounts1 + dcounts2\n",
        "cmp('dcounts', dcounts, counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y8HNLAhLnl9",
        "outputId": "7e76fcef-1fe6-45e9-86d9-0b4088bd4ac8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcounts         | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dnorm_logits\n",
        "$$counts = e^{\\text{norm_logits}}\n",
        "$$\n",
        "$$\\dfrac{\\delta counts}{\\delta \\text{norm_logits}} = e^{\\text{norm_logits}}\n",
        "$$"
      ],
      "metadata": {
        "id": "uuwxEfgywi2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dnorm_logits = counts * dcounts\n",
        "cmp('dnorm_logits', dnorm_logits, norm_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVKWhVSRwlZo",
        "outputId": "de202281-dde4-4cfa-bbea-6c0cf7c2474f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dnorm_logits    | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZkwOMb_4hG7",
        "outputId": "6a7e5fdc-884e-48ce-c158-99856453b8f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dlogit_maxes\n",
        "$$\\text{norm_logits}=logits_i - \\text{logit_maxes}_i \\quad \\text{for }i \\in [0,N)\n",
        "$$\n",
        "The dimension of logit_maxes is (N,1)\n",
        "\n",
        "$$\\dfrac{\\delta \\text{norm_logits}}{\\delta \\text{logit_maxes}} = -\\sum_{j}^{\\text{vocab_size}}1\n",
        "$$"
      ],
      "metadata": {
        "id": "QR5zcUsMypVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogit_maxes = -dnorm_logits\n",
        "dlogit_maxes = dlogit_maxes.sum(dim=1, keepdim=True)\n",
        "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s6uXNI_0-4l",
        "outputId": "d3161fef-cd0c-4b37-8831-dce7e0a61e57"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogit_maxes    | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit_maxes.shape, dlogit_maxes.shape, logit_maxes.grad[0], dlogit_maxes[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htjF-XEF4Ac9",
        "outputId": "97650b7e-2479-49a5-cc22-d83dbe3b9787"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1]),\n",
              " torch.Size([32, 1]),\n",
              " tensor([-3.7253e-09]),\n",
              " tensor(-3.7253e-09, grad_fn=<SumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dlogits\n",
        "logits are used twice in forward pass, once in norm_logits, once in logit_maxes.\n",
        "\n",
        "For norm_logits:\n",
        "$$\\text{norm_logits}=logits - \\text{logit_maxes}\n",
        "$$\n",
        "$$\\dfrac{\\delta \\text{norm_logits}}{\\delta logits} = 1\n",
        "$$\n",
        "\n",
        "For logit_maxes:\n",
        "$$\\text{logit_maxes}=max(logits_j)  \\quad \\text{for }j \\in [0, \\text{vocab_size})\n",
        "$$\n",
        "Therefore, for each row, only the max value index contributes to the gradient, the rest of the gradient is zero.\n",
        "$$\\dfrac{\\delta \\text{logit_maxes}}{\\delta logits}=\n",
        "\\begin{cases}\n",
        "1 & \\quad \\text{when }logits_j \\text{ is the max of the sample}\\\\\n",
        "0 & \\quad \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "6MUADJr1xu8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits1 = dnorm_logits\n",
        "\n",
        "dlogits2 = torch.zeros_like(logits)\n",
        "#dlogits2[range(logits.shape[0]), torch.argmax(logits, dim=1)]=1\n",
        "# alternatively, the above can be done as\n",
        "dlogits2[range(logits.shape[0]), logits.max(dim=1).indices] =1\n",
        "dlogits2 *= dlogit_maxes\n",
        "\n",
        "# alternatively, the above can be done as one-hot\n",
        "#dlogits2 = F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
        "\n",
        "dlogits = dlogits1 + dlogits2\n",
        "cmp('dlogits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUlyIz-Hx1eK",
        "outputId": "4adc7b28-f1be-426b-87e6-cb0e61c664b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogits         | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "FQezDYzoYAUC",
        "outputId": "a49a8e50-6738-4e34-f930-6abaee70a696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7, 14,  4,  8, 21, 13, 22, 24, 13, 22, 22, 22,  8, 18, 22, 22, 24, 25,\n",
              "        19,  5, 15,  2,  2,  7, 25,  9, 17, 24, 21, 24,  9, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits2[range(logits.shape[0]), torch.argmax(logits, dim=1)]=1\n",
        "dlogits2"
      ],
      "metadata": {
        "id": "znx4r9VIWUwm",
        "outputId": "413008df-7f1c-41df-f92f-f2be352910fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., 1., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., 1., -0., -0., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., 1., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         1., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., 1., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [-0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [-0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., 1., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<IndexPutBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.max(dim=1).indices"
      ],
      "metadata": {
        "id": "ymrktLq6YFf_",
        "outputId": "3fa4391f-ae58-401f-ce97-4748fc363eac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7, 14,  4,  8, 21, 13, 22, 24, 13, 22, 22, 22,  8, 18, 22, 22, 24, 25,\n",
              "        19,  5, 15,  2,  2,  7, 25,  9, 17, 24, 21, 24,  9, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits2 = torch.zeros_like(logits)\n",
        "dlogits2[range(logits.shape[0]), logits.max(dim=1).indices] =1\n",
        "dlogits2"
      ],
      "metadata": {
        "id": "EhvAxLr_Xr5l",
        "outputId": "1d87dcf2-699d-4b88-dde5-bfa992f775ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(logits.max(1).indices, num_classes=logits.shape[1])"
      ],
      "metadata": {
        "id": "RwxIKICNaFCA",
        "outputId": "f083e5c0-1666-4fec-f896-b26b66b2034b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 - backward of output layer"
      ],
      "metadata": {
        "id": "QcBnehFN-93U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "logits = h @ W2 + b2\n",
        "\n",
        "manipulate to match the dimensions."
      ],
      "metadata": {
        "id": "ur-q2bec_Igd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2.shape, dlogits.shape, h.shape, b2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tawsmCSC_jRe",
        "outputId": "3e9df182-193a-4c25-a9ee-7ded3dc07a5e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([200, 27]),\n",
              " torch.Size([32, 27]),\n",
              " torch.Size([32, 200]),\n",
              " torch.Size([27]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dW2 = h.T @ dlogits\n",
        "cmp('dW2', dW2, W2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqihgwvy_BjP",
        "outputId": "fb67a228-529e-4530-a94b-9e706734128a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dW2             | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#db2 = torch.ones_like(b2) * dlogits\n",
        "db2 = dlogits.sum(dim=0) # db2 dim is (vocab_size), so it contributes 1 per column\n",
        "cmp('db2', db2, b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lFEMby-Anw1",
        "outputId": "4e62b6c9-936d-4d2c-8c1e-b98d10251afe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "db2             | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh = dlogits @ W2.T\n",
        "cmp('dh', dh, h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm2zyks5DHoI",
        "outputId": "09af2969-aa97-405d-afde-816e7c8b7b8a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh              | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 - backward of activation\n",
        "h = torch.tanh(h_preact)\n",
        "\n",
        "gradient of tanh(x) is 1-tanh(x)**2"
      ],
      "metadata": {
        "id": "c6mqXwa1Cozj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dh_preact = (1.0- h**2) * dh\n",
        "cmp('dh_preact', dh_preact, h_preact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDfxAkJdB6vF",
        "outputId": "1c7f38b3-e942-4a55-84e5-894eb025b739"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh_preact       | exact: False | approx: True  | maxdiff: 4.656612873077393e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h.grad.dtype"
      ],
      "metadata": {
        "id": "B0nctBjqiBwi",
        "outputId": "6ee15cef-dcf0-45cc-a5c9-925a6c4908ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4 - backward of Batch Norm layer"
      ],
      "metadata": {
        "id": "cXCha0D4Bg1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gamma, beta, x_hat\n",
        "h_preact = bn_gamma * x_hat + bn_bias"
      ],
      "metadata": {
        "id": "Bg3wclMqBrTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_gamma.shape, h_preact.shape, bn_bias.shape, x_hat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulzeOclHEmrt",
        "outputId": "96f1a3b4-5651-4360-e471-836423c14101"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 200]),\n",
              " torch.Size([32, 200]),\n",
              " torch.Size([1, 200]),\n",
              " torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_gamma = x_hat * dh_preact\n",
        "dbn_gamma = dbn_gamma.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_gamma', dbn_gamma, bn_gamma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKii5_L4EjM8",
        "outputId": "7321ae1f-b6e4-41b6-b240-c330ac0742bf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_gamma       | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_bias = dh_preact.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_bias', dbn_bias, bn_bias)"
      ],
      "metadata": {
        "id": "b6JGxUY37Y_k",
        "outputId": "3a777922-c8ed-4333-cc52-b281fbba89d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_bias        | exact: False | approx: True  | maxdiff: 3.725290298461914e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dx_hat = bn_gamma * dh_preact\n",
        "cmp('dx_hat', dx_hat, x_hat)"
      ],
      "metadata": {
        "id": "BcdaV1qA7pdF",
        "outputId": "9d539563-f01e-474a-c38a-f147ca6a36d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dx_hat          | exact: False | approx: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bn_varinv\n",
        "x_hat = bn_diff * bn_varinv"
      ],
      "metadata": {
        "id": "qze_SeQa78fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_hat.shape, bn_diff.shape, bn_varinv.shape"
      ],
      "metadata": {
        "id": "7Iftu-QA8UuB",
        "outputId": "9cd5799a-e947-444f-aa16-47c5fd625b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([32, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_varinv = bn_diff * dx_hat\n",
        "dbn_varinv = dbn_varinv.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_varinv', dbn_varinv, bn_varinv)"
      ],
      "metadata": {
        "id": "Oe6qNZPX8H7v",
        "outputId": "7492096f-3373-42c2-933b-ca46d0f100cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_varinv      | exact: False | approx: True  | maxdiff: 3.725290298461914e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bn_var\n",
        "bn_varinv = (bn_var + 1e-5)**-0.5"
      ],
      "metadata": {
        "id": "suf7fMhx8twK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_var.shape, bn_varinv.shape"
      ],
      "metadata": {
        "id": "14XrqYu79dMq",
        "outputId": "baf3a7fe-9622-4620-ead7-45b3d56c1c2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_var = -0.5 * ((bn_var+1e-5)**-1.5)\n",
        "dbn_var *= dbn_varinv\n",
        "cmp('dbn_var', dbn_var, bn_var)"
      ],
      "metadata": {
        "id": "L_M3uDSr80HT",
        "outputId": "c1087822-2eb1-4f4c-f871-2a4343b595a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_var         | exact: False | approx: True  | maxdiff: 6.984919309616089e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bn_diff2\n",
        "bn_var = 1/(batch_size-1) * bn_diff2.sum(dim=0, keepdim=True)"
      ],
      "metadata": {
        "id": "3ZzmSnsqC2_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_diff2.shape, dbn_var.shape"
      ],
      "metadata": {
        "id": "FQ4UDOPqDVPu",
        "outputId": "5c8fc8b4-e281-49b3-dea4-40dd10291c0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff2 = 1/(batch_size-1) * dbn_var\n",
        "dbn_diff2 = dbn_diff2.expand(bn_diff2.shape) # expand to the right shape\n",
        "\n",
        "# alternatively, the above can be done as\n",
        "#dbn_diff2 = 1/(batch_size-1) * torch.ones_like(bn_diff2) *dbn_var\n",
        "\n",
        "cmp('dbn_diff2', dbn_diff2, bn_diff2)\n",
        "#dbn_diff2"
      ],
      "metadata": {
        "id": "lhATtBVhC7b2",
        "outputId": "6fcd9b0d-1068-43a5-b259-bad80f58ea20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_diff2       | exact: False | approx: True  | maxdiff: 2.1827872842550278e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bn_diff\n",
        "bn_diff appears in 2 places: x_hat, bn_var, bn_diff2\n",
        "\n",
        "for x_hat:\n",
        "x_hat = bn_diff * bn_varinv\n",
        "\n",
        "for bn_diff2:\n",
        "bn_diff2 = bn_diff ** 2"
      ],
      "metadata": {
        "id": "3J4Ddi4eASxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff_1 = bn_varinv * dx_hat\n",
        "dbn_diff_2 = 2 * bn_diff * dbn_diff2\n",
        "dbn_diff = dbn_diff_1 + dbn_diff_2\n",
        "\n",
        "cmp('dbn_diff', dbn_diff, bn_diff)"
      ],
      "metadata": {
        "id": "mus6E5TbAg0-",
        "outputId": "c83576d9-e233-4ebe-e7da-444ccfc45fcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_diff        | exact: False | approx: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff.shape, bn_diff.shape"
      ],
      "metadata": {
        "id": "u42uW4SxJYIt",
        "outputId": "e4810f58-b01b-4b03-dd56-126a366108a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bn_mean\n",
        "bn_diff = (h_prebn - bn_mean)"
      ],
      "metadata": {
        "id": "K0E3PDM7GA7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_mean = -dbn_diff\n",
        "dbn_mean = dbn_mean.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_mean', dbn_mean, bn_mean)"
      ],
      "metadata": {
        "id": "-S8DEAYFHo0v",
        "outputId": "9c44dcc1-159d-4d01-fa17-ed6e86dcf530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_mean        | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff.shape, bn_mean.shape, dbn_mean.shape, bn_mean.grad.shape"
      ],
      "metadata": {
        "id": "lC8R-6XtoPF8",
        "outputId": "204c4c61-15c0-425e-96b2-020e65ca0487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]),\n",
              " torch.Size([1, 200]),\n",
              " torch.Size([1, 200]),\n",
              " torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###h_prebn\n",
        "h_prebn appears twice: once in bn_mean, once in bn_diff\n",
        "\n",
        "from bn_mean:\n",
        "bn_mean = 1/batch_size*h_prebn.sum(dim=0, keepdim=True)\n",
        "\n",
        "from bn_diff:\n",
        "bn_diff = (h_prebn - bn_mean)"
      ],
      "metadata": {
        "id": "sBShut01J1hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dh_prebn1 = dbn_diff.clone()\n",
        "dh_prebn2 = 1/batch_size * dbn_mean\n",
        "dh_prebn2 = dh_prebn2.expand(h_prebn.shape) # or can mult by torch.ones instead\n",
        "dh_prebn = dh_prebn1 + dh_prebn2\n",
        "cmp('dh_prebn', dh_prebn, h_prebn)"
      ],
      "metadata": {
        "id": "0TAzGbiJGHBu",
        "outputId": "ff567384-c274-4e4f-da65-4ccae08eba51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh_prebn        | exact: False | approx: True  | maxdiff: 6.984919309616089e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - backward of hidden layer\n",
        "h_prebn = embcat @ W1 + b1 # (batch_size, hidden_dim)"
      ],
      "metadata": {
        "id": "fl4dxf5GKjZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dW1 = embcat.T @ dh_prebn\n",
        "cmp('dW1', dW1, W1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezz7DoBMBo79",
        "outputId": "eb766fc0-a288-425d-b3e4-1e994ed5dc63"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dW1             | exact: False | approx: True  | maxdiff: 5.587935447692871e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dW1[0,:5], W1.grad[0,:5]"
      ],
      "metadata": {
        "id": "pW_9toJCMcVJ",
        "outputId": "e19e2b62-4552-468b-afae-01d91a197226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0002, -0.0157, -0.0017, -0.0064, -0.0011], grad_fn=<SliceBackward0>),\n",
              " tensor([ 0.0002, -0.0157, -0.0017, -0.0064, -0.0011]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dembcat = dh_prebn @ W1.T\n",
        "cmp('dembcat', dembcat, embcat)"
      ],
      "metadata": {
        "id": "b67a2202OXLm",
        "outputId": "5ab99eb8-fe2e-4dcd-acd6-dae1f28fc91e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dembcat         | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embcat.shape, W1.shape, h_prebn.shape"
      ],
      "metadata": {
        "id": "DWnaUimlOd_R",
        "outputId": "d3dff652-1cba-450b-f623-6287351bf555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 30]), torch.Size([30, 200]), torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db1 = torch.ones_like(b1) * dh_prebn\n",
        "db1 = db1.sum(dim=0)\n",
        "cmp('db1', db1, b1)"
      ],
      "metadata": {
        "id": "dGrFAT2lK6uF",
        "outputId": "6e756f82-2e1e-4c53-8ac3-9742513caf7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "db1             | exact: False | approx: True  | maxdiff: 6.51925802230835e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_prebn.shape, b1.shape, db1.shape, db1[:15], b1.grad[:15]"
      ],
      "metadata": {
        "id": "BU3etu1wKs31",
        "outputId": "30a11f4b-f036-459e-8502-fd6b6d3dc5b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]),\n",
              " torch.Size([200]),\n",
              " torch.Size([200]),\n",
              " tensor([ 2.9104e-10,  4.6566e-10, -4.6566e-10,  9.3132e-10,  0.0000e+00,\n",
              "          1.1642e-10,  4.6566e-10,  4.6566e-10,  0.0000e+00, -9.3132e-10,\n",
              "         -4.6566e-10,  0.0000e+00,  2.7940e-09, -5.8208e-10,  0.0000e+00],\n",
              "        grad_fn=<SliceBackward0>),\n",
              " tensor([ 4.6566e-10,  9.3132e-10,  0.0000e+00, -1.8626e-09,  9.3132e-10,\n",
              "          1.1642e-10,  4.6566e-10,  0.0000e+00,  0.0000e+00, -9.3132e-10,\n",
              "          0.0000e+00,  0.0000e+00,  1.0477e-09,  0.0000e+00,  0.0000e+00]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 - backward of embedding\n",
        "emb = C[xs] # (batch_size, block_size, hidden_dim)\n",
        "\n",
        "embcat = emb.view(emb.shape[0], -1)"
      ],
      "metadata": {
        "id": "Idz1PnXwNtBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C.shape, emb.shape, dembcat.shape, xs.shape"
      ],
      "metadata": {
        "id": "-dHhwLlmN8cO",
        "outputId": "0027bbd6-2d07-4677-b2d3-60fc77034930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([27, 10]),\n",
              " torch.Size([32, 3, 10]),\n",
              " torch.Size([32, 30]),\n",
              " torch.Size([32, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demb = dembcat.view(emb.shape)\n",
        "cmp('demb', demb, emb)"
      ],
      "metadata": {
        "id": "aJgpmMOLPJz-",
        "outputId": "23902bb2-7175-4dae-e5da-93a8b658c526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "demb            | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dC = torch.zeros_like(C)\n",
        "# for i in range(xs.shape[0]):\n",
        "#   for j in range(xs.shape[1]):\n",
        "#     ix = xs[i,j]\n",
        "#     dC[ix] += demb[i,j]\n",
        "dC = torch.einsum('abc,abg->cg', F.one_hot(xs, vocab_size).float(), demb)\n",
        "cmp('dC', dC, C)"
      ],
      "metadata": {
        "id": "xHhhGkgpPXN-",
        "outputId": "2c0143e0-7fd3-4428-a68c-1b06ec1ca11c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dC              | exact: False | approx: True  | maxdiff: 1.1175870895385742e-08\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "makemore_backprop.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}