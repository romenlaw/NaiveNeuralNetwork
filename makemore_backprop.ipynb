{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romenlaw/NaiveNeuralNetwork/blob/main/makemore_backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4f4JG1gdKqj"
      },
      "source": [
        "#Makemore - backprop ninja"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare datasets"
      ],
      "metadata": {
        "id": "vTLLwG6T_Srt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/romenlaw/NaiveNeuralNetwork/main/names.txt"
      ],
      "metadata": {
        "id": "WnJ_g9N870O8",
        "outputId": "fc9a0541-f311-4d98-dfc0-8e51f8c32938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  222k  100  222k    0     0   713k      0 --:--:-- --:--:-- --:--:--  714k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "kI-rQ1qpCWoV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "len(words), max(len(w) for w in words), words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RRwKoRN_V0p",
        "outputId": "a7a761c5-32f9-4758-f728-7a0eeb0e543c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32033,\n",
              " 15,\n",
              " ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(list(set(''.join(words))))\n",
        "vocab.insert(0, '.')\n",
        "itos = { i:s for i,s in enumerate(vocab)}\n",
        "stoi = { s:i for i,s in enumerate(vocab)}\n",
        "vocab_size = len(vocab)  # 27"
      ],
      "metadata": {
        "id": "rWeh-qTNAOxO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3  # context size - 3 tokens\n",
        "\n",
        "def build_dataset(words):\n",
        "  \"\"\"returns torch tensors X, Y where\n",
        "  X is a list of n-grams indices covering the whole words list, where n=block_size\n",
        "  Y is a list of indices predicting each n-gram in X\n",
        "  \"\"\"\n",
        "  X, Y = [], []\n",
        "\n",
        "  #for w in words[:5]:\n",
        "  for w in words:\n",
        "    context = [0] * block_size # repeat '.' to fill block_size\n",
        "    for ch in w+'.':\n",
        "      ix = stoi[ch]\n",
        "      #print(' '.join([itos[i] for i in context]), '---->', itos[ix])\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix]\n",
        "\n",
        "  return torch.tensor(X), torch.tensor(Y)\n",
        "\n",
        "X, Y = build_dataset(words)\n",
        "#X[:32], Y[:32]\n",
        "\n",
        "# split the data into 3 sets\n",
        "# 80% for training set\n",
        "# 10% for validation/development\n",
        "# 10% for testing\n",
        "import random\n",
        "random.seed(42)\n",
        "n1 = int(len(words) * .8)\n",
        "n2 = int(len(words) * .9)\n",
        "random.shuffle(words) # shuffle is in-place\n",
        "X_train, Y_train = build_dataset(words[:n1])\n",
        "X_dev, Y_dev = build_dataset(words[n1:n2])\n",
        "X_test, Y_test = build_dataset(words[n2:])\n",
        "\n",
        "#len(words[n1:n2])\n",
        "(X_train.shape, Y_train.shape), (X_dev.shape, Y_dev.shape), (X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_wuMWU1BUFe",
        "outputId": "29de2c24-3412-4536-d682-a4998f152720"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((torch.Size([182625, 3]), torch.Size([182625])),\n",
              " (torch.Size([22655, 3]), torch.Size([22655])),\n",
              " (torch.Size([22866, 3]), torch.Size([22866])))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utilities"
      ],
      "metadata": {
        "id": "_Zrl2yoKDHSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utility to compare our manual gradients with pytorch gradients\n",
        "def cmp(s, dt, t):\n",
        "  \"\"\"Compares dt and t.grad to see if their values are equal or close\n",
        "  s - name of the parameter being compared, used in printing only\n",
        "  dt - tensor of manually calculated gradient\n",
        "  t - torch tensor\n",
        "  \"\"\"\n",
        "  ex = torch.all(dt==t.grad).item()\n",
        "  apx = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approx: {str(apx):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "x9d-letYDPF7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP\n",
        "In the parameter initialisation, we use non-standard values to see their effect; otherwise, for example, zeros can mask out any incorrect values."
      ],
      "metadata": {
        "id": "VAOQhg9HNNyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 10\n",
        "hidden_dim = 200\n",
        "\n",
        "g = torch.Generator().manual_seed(20240824)\n",
        "C = torch.randn((vocab_size, embed_dim),  generator=g)\n",
        "\n",
        "# hidden layer\n",
        "fan_in = embed_dim*block_size # we concat multiple C's to feed into hidden layer\n",
        "W1 = torch.randn((fan_in, hidden_dim), generator=g) * (5/3 / fan_in**0.5)\n",
        "b1 = torch.randn(hidden_dim,           generator=g) * 0.1 # experiment\n",
        "# output layer\n",
        "W2 = torch.randn((hidden_dim, vocab_size), generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,               generator=g) * 0.1 # experiment with non-zero\n",
        "\n",
        "# batch normalisation 1D layer placed after hidden layer, hence dim=hidden_dim\n",
        "bn_gamma = torch.randn((1, hidden_dim),    generator=g) * 0.1 + 1.0\n",
        "bn_bias = torch.randn((1, hidden_dim),     generator=g) * 0.1\n",
        "#bn_running_mean = torch.zeros((1, hidden_dim))\n",
        "#bn_running_std = torch.ones((1, hidden_dim))\n",
        "\n",
        "# the above are initialised with non-standard values to magnify any incorrect values\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bn_gamma, bn_bias]\n",
        "print('total params: ', sum([p.nelement() for p in parameters]))\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4EIrTkZNPpo",
        "outputId": "f1745f99-d054-4873-a9c7-89866ac02c0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total params:  12297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1 - slow pass\n",
        "This exercise breaks down the forward pass into atomic individual steps, then back prop each step."
      ],
      "metadata": {
        "id": "ndKNtGStGcgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training - extended version\n",
        "We expand the forward pass into step by step calculations so that we can manually calculate the gradient step by step as well. For Cross Entropy loss function, see [pyTorch doco](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss).\n",
        "\n",
        "We don't call the loss.backward(). Instead, we will do it manually."
      ],
      "metadata": {
        "id": "T9c-gp2PM-Rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# understanding tensor.values, which only works on sparse tensor\n",
        "t = torch.randn((2,3))\n",
        "sparse_tensor = t.max(dim=1, keepdim=True)\n",
        "t, '-----------', sparse_tensor, '------------', sparse_tensor.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4UqInlQLqw4",
        "outputId": "02751176-ea13-4308-b5ee-7c21dc354821"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.1484,  2.3629,  0.1412],\n",
              "         [-1.2185, -1.6495,  0.1812]]),\n",
              " '-----------',\n",
              " torch.return_types.max(\n",
              " values=tensor([[2.3629],\n",
              "         [0.1812]]),\n",
              " indices=tensor([[1],\n",
              "         [2]])),\n",
              " '------------',\n",
              " tensor([[2.3629],\n",
              "         [0.1812]]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # construct mini-batch:\n",
        "  # generate a list of random indices, length of list if batch_size\n",
        "  ix = torch.randint(low=0, high=X_train.shape[0], size=(batch_size,), generator=g)\n",
        "  xs = X_train[ix]  # (batch_size, block_size)\n",
        "  ys = Y_train[ix]  # (batch_size)\n",
        "\n",
        "  ##################################\n",
        "  # forward pass (expanded version)\n",
        "  ##################################\n",
        "  # embedding ---------------------------\n",
        "  emb = C[xs] # (batch_size, block_size, hidden_dim)\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  # hidden layer ------------------------\n",
        "  h_prebn = embcat @ W1 + b1 # (batch_size, hidden_dim)\n",
        "  # BN layer (expended version) ----------------------------\n",
        "  #bn_mean = h_prebn.mean(dim=0, keepdim=True)\n",
        "  bn_mean = 1/batch_size*h_prebn.sum(dim=0, keepdim=True)\n",
        "  #bn_std = h_prebn.std(dim=0, keepdim=True)\n",
        "  bn_diff = (h_prebn - bn_mean)\n",
        "  bn_diff2 = bn_diff ** 2\n",
        "  bn_var = 1/(batch_size-1) * bn_diff2.sum(dim=0, keepdim=True) # Bessel's correction, divide by m-1 not m\n",
        "  bn_varinv = (bn_var + 1e-5)**-0.5  # 1/sqrt(var+eps)\n",
        "  x_hat = bn_diff * bn_varinv\n",
        "  h_preact = bn_gamma * x_hat + bn_bias\n",
        "  #with torch.no_grad():\n",
        "  #  bn_running_mean = 0.999 * bn_running_mean + 0.001 * bn_mean\n",
        "  #  bn_running_std = 0.999 * bn_running_std + 0.001 * bn_std\n",
        "  # Non-linearity ----------------------\n",
        "  h = torch.tanh(h_preact)  # (batch_size, hidden_dim)\n",
        "  # output layer -----------------------\n",
        "  logits = h @ W2 + b2 # (hidden_dim, vocab_size)\n",
        "  # loss function (extended version) ----------------------\n",
        "  #loss = F.cross_entropy(logits, ys)\n",
        "  logit_maxes = logits.max(dim=1, keepdim=True).values  # (hidden_dim, 1)\n",
        "  norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "  counts = norm_logits.exp()  # (batch_size, vocab_size)\n",
        "  counts_sum = counts.sum(dim=1, keepdim=True) # (batch_size, 1)\n",
        "  counts_sum_inv = counts_sum ** -1  # (batch_size, 1)\n",
        "  probs = counts * counts_sum_inv  # (batch_size, vocab_size)\n",
        "  logprobs = probs.log()   # (batch_size, vocab_size)\n",
        "  loss = -logprobs[range(batch_size), ys].mean()  # scalar\n",
        "\n",
        "  ################\n",
        "  # backward pass\n",
        "  ################\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  for t in [logprobs, probs, counts_sum_inv, counts_sum, counts,\n",
        "            norm_logits, logit_maxes, logits,\n",
        "            h, h_preact, x_hat, bn_varinv, bn_var, bn_diff2, bn_diff, bn_mean,\n",
        "            h_prebn, embcat, emb ]:\n",
        "    t.retain_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  ###############\n",
        "  # update\n",
        "  ###############\n",
        "  # lr = 0.1 if i<100000 else 0.01\n",
        "  # for p in parameters:\n",
        "  #   p.data += -lr * p.grad\n",
        "\n",
        "  # # tracking\n",
        "  # lossi.append(loss)\n",
        "  # if i%10000 == 0:\n",
        "  #   print('%6d/%7d %2.10f' % (i, max_steps, loss))\n",
        "\n",
        "  # if i>1000:\n",
        "  break\n",
        "print('%6d/%7d %2.10f' % (i, max_steps, loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOpGCG2TNAkI",
        "outputId": "e21c497c-8288-4e05-9b6b-65cd411a6e14"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0/ 200000 3.5082895756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb19DCBUFD3W",
        "outputId": "b7ef8501-09ab-4164-b256-77f133463170"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - backward pass of loss function"
      ],
      "metadata": {
        "id": "ry8Xbe9-DPNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dlogprobs\n",
        "logprobs is dimension (N, vocab_size) , where N = batch_size\n",
        "$$loss = -\\dfrac{1}{N}\\sum_{i=1}^{N}logprobs_{i, y_i}$$\n",
        "For the loss function, only elements at indices $[i, y_i]$ contribute to the loss. The rest are not used. Therefore, the unused elements have gradient 0.\n",
        "$$\\dfrac{\\delta loss}{\\delta logprobs}=\n",
        "\\begin{cases}\n",
        "-\\dfrac{1}{N} & \\quad \\text{at positions }{i},{y_i}\\\\\n",
        "0 & \\quad \\text{elsewhere}\n",
        "\\end{cases}\n",
        "$$"
      ],
      "metadata": {
        "id": "zcMTxreLHKO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(batch_size), ys] = -1/batch_size\n",
        "cmp('dlogprobs', dlogprobs, logprobs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek7Mmk4fO9kt",
        "outputId": "6568e813-230b-4c48-a739-71d2e708284e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogprobs       | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dprobs\n",
        "$$logprobs = \\ln(probs)$$\n",
        "$$\\dfrac{\\delta logprobs}{\\delta probs} = \\dfrac{1}{probs}\n",
        "$$"
      ],
      "metadata": {
        "id": "i_6hGt3IJduM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dprobs = 1/probs * dlogprobs\n",
        "cmp('dprobs', dprobs, probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZAWM-h4T_3y",
        "outputId": "d89e90f7-34e8-4f00-807e-f5ca6e407f4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dprobs          | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dcount_sum_inv\n",
        "\n",
        "$$probs = counts * \\text{counts_sum_inv}\n",
        "$$\n",
        "$$\\dfrac{\\delta probs}{\\delta \\text{counts_sum_inv}} = counts\n",
        "$$\n",
        "Note that the dimension of counts_sum_inv is (N, 1), so does its derivative."
      ],
      "metadata": {
        "id": "ocS5fuREeaw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum_inv = counts * dprobs\n",
        "dcounts_sum_inv = dcounts_sum_inv.sum(dim=1, keepdim=True)\n",
        "cmp('dcounts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUwrnaS7KURu",
        "outputId": "9fdc8047-be86-47ba-8cb2-ba67d556ef89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcounts_sum_inv | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dcounts_sum\n",
        "$$\\text{counts_sum_inv} = \\text{counts_sum}^{-1}\n",
        "$$\n",
        "$$\\dfrac{\\delta\\text{counts_sum_inv}}{\\delta\\text{counts_sum}} = -\\text{counts_sum}^{-2}\n",
        "$$"
      ],
      "metadata": {
        "id": "91_4MFMKh1aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum=-counts_sum**-2\n",
        "dcounts_sum *= dcounts_sum_inv\n",
        "cmp('dcounts_sum', dcounts_sum, counts_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2VR1zGJKonc",
        "outputId": "287b4224-3f17-46fc-e811-b175c6ecaa2f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcounts_sum     | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum[0], counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY4dWJRcvU8T",
        "outputId": "d3876d8b-649a-409c-e452-d2d3024fd83a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0040], grad_fn=<SelectBackward0>), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dcounts\n",
        "counts is used twice in the forward pass: once in counts_sum, another in probs.\n",
        "for counts_sum:\n",
        "$$\\text{counts_sum} = \\sum_{j=1}^{\\text{vocab_size}}counts_{i,j}\n",
        "$$\n",
        "$$\\dfrac{\\delta \\text{counts_sum}}{\\delta counts} = 1_{N, \\text{vocab_size}}\n",
        "$$\n",
        "Note that the 1 is same dimension as counts, i.e. (N, vocab_size)\n",
        "\n",
        "For probs:\n",
        "$$probs = counts * \\text{counts_sum_inv}\n",
        "$$\n",
        "$$\\dfrac{\\delta probs}{\\delta counts} = \\text{counts_sum_inv}\n",
        "$$"
      ],
      "metadata": {
        "id": "68bhFVV7i2n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts1 = torch.ones_like(counts) * dcounts_sum\n",
        "dcounts2 = counts_sum_inv * dprobs\n",
        "dcounts = dcounts1 + dcounts2\n",
        "cmp('dcounts', dcounts, counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y8HNLAhLnl9",
        "outputId": "7e76fcef-1fe6-45e9-86d9-0b4088bd4ac8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcounts         | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dnorm_logits\n",
        "$$counts = e^{\\text{norm_logits}}\n",
        "$$\n",
        "$$\\dfrac{\\delta counts}{\\delta \\text{norm_logits}} = e^{\\text{norm_logits}}\n",
        "$$"
      ],
      "metadata": {
        "id": "uuwxEfgywi2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dnorm_logits = counts * dcounts\n",
        "cmp('dnorm_logits', dnorm_logits, norm_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVKWhVSRwlZo",
        "outputId": "de202281-dde4-4cfa-bbea-6c0cf7c2474f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dnorm_logits    | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZkwOMb_4hG7",
        "outputId": "6a7e5fdc-884e-48ce-c158-99856453b8f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dlogit_maxes\n",
        "$$\\text{norm_logits}=logits_i - \\text{logit_maxes}_i \\quad \\text{for }i \\in [0,N)\n",
        "$$\n",
        "The dimension of logit_maxes is (N,1)\n",
        "\n",
        "$$\\dfrac{\\delta \\text{norm_logits}}{\\delta \\text{logit_maxes}} = -\\sum_{j}^{\\text{vocab_size}}1\n",
        "$$"
      ],
      "metadata": {
        "id": "QR5zcUsMypVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogit_maxes = -dnorm_logits\n",
        "dlogit_maxes = dlogit_maxes.sum(dim=1, keepdim=True)\n",
        "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s6uXNI_0-4l",
        "outputId": "d3161fef-cd0c-4b37-8831-dce7e0a61e57"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogit_maxes    | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit_maxes.shape, dlogit_maxes.shape, logit_maxes.grad[0], dlogit_maxes[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htjF-XEF4Ac9",
        "outputId": "97650b7e-2479-49a5-cc22-d83dbe3b9787"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1]),\n",
              " torch.Size([32, 1]),\n",
              " tensor([-3.7253e-09]),\n",
              " tensor(-3.7253e-09, grad_fn=<SumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dlogits\n",
        "logits are used twice in forward pass, once in norm_logits, once in logit_maxes.\n",
        "\n",
        "For norm_logits:\n",
        "$$\\text{norm_logits}=logits - \\text{logit_maxes}\n",
        "$$\n",
        "$$\\dfrac{\\delta \\text{norm_logits}}{\\delta logits} = 1\n",
        "$$\n",
        "\n",
        "For logit_maxes:\n",
        "$$\\text{logit_maxes}=max(logits_j)  \\quad \\text{for }j \\in [0, \\text{vocab_size})\n",
        "$$\n",
        "Therefore, for each row, only the max value index contributes to the gradient, the rest of the gradient is zero.\n",
        "$$\\dfrac{\\delta \\text{logit_maxes}}{\\delta logits}=\n",
        "\\begin{cases}\n",
        "1 & \\quad \\text{when }logits_j \\text{ is the max of the sample}\\\\\n",
        "0 & \\quad \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "6MUADJr1xu8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits1 = dnorm_logits\n",
        "\n",
        "dlogits2 = torch.zeros_like(logits)\n",
        "#dlogits2[range(logits.shape[0]), torch.argmax(logits, dim=1)]=1\n",
        "# alternatively, the above can be done as\n",
        "dlogits2[range(logits.shape[0]), logits.max(dim=1).indices] =1\n",
        "dlogits2 *= dlogit_maxes\n",
        "\n",
        "# alternatively, the above can be done as one-hot\n",
        "#dlogits2 = F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
        "\n",
        "dlogits = dlogits1 + dlogits2\n",
        "cmp('dlogits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUlyIz-Hx1eK",
        "outputId": "4adc7b28-f1be-426b-87e6-cb0e61c664b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogits         | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "FQezDYzoYAUC",
        "outputId": "a49a8e50-6738-4e34-f930-6abaee70a696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7, 14,  4,  8, 21, 13, 22, 24, 13, 22, 22, 22,  8, 18, 22, 22, 24, 25,\n",
              "        19,  5, 15,  2,  2,  7, 25,  9, 17, 24, 21, 24,  9, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits2[range(logits.shape[0]), torch.argmax(logits, dim=1)]=1\n",
        "dlogits2"
      ],
      "metadata": {
        "id": "znx4r9VIWUwm",
        "outputId": "413008df-7f1c-41df-f92f-f2be352910fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., 1., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., 1., -0., -0., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., 1., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         1., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., 1., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [-0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [-0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., 1., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<IndexPutBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.max(dim=1).indices"
      ],
      "metadata": {
        "id": "ymrktLq6YFf_",
        "outputId": "3fa4391f-ae58-401f-ce97-4748fc363eac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7, 14,  4,  8, 21, 13, 22, 24, 13, 22, 22, 22,  8, 18, 22, 22, 24, 25,\n",
              "        19,  5, 15,  2,  2,  7, 25,  9, 17, 24, 21, 24,  9, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits2 = torch.zeros_like(logits)\n",
        "dlogits2[range(logits.shape[0]), logits.max(dim=1).indices] =1\n",
        "dlogits2"
      ],
      "metadata": {
        "id": "EhvAxLr_Xr5l",
        "outputId": "1d87dcf2-699d-4b88-dde5-bfa992f775ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(logits.max(1).indices, num_classes=logits.shape[1])"
      ],
      "metadata": {
        "id": "RwxIKICNaFCA",
        "outputId": "f083e5c0-1666-4fec-f896-b26b66b2034b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 - backward of output layer"
      ],
      "metadata": {
        "id": "QcBnehFN-93U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "logits = h @ W2 + b2\n",
        "\n",
        "manipulate to match the dimensions."
      ],
      "metadata": {
        "id": "ur-q2bec_Igd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2.shape, dlogits.shape, h.shape, b2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tawsmCSC_jRe",
        "outputId": "3e9df182-193a-4c25-a9ee-7ded3dc07a5e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([200, 27]),\n",
              " torch.Size([32, 27]),\n",
              " torch.Size([32, 200]),\n",
              " torch.Size([27]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dW2 = h.T @ dlogits\n",
        "cmp('dW2', dW2, W2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqihgwvy_BjP",
        "outputId": "fb67a228-529e-4530-a94b-9e706734128a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dW2             | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#db2 = torch.ones_like(b2) * dlogits\n",
        "db2 = dlogits.sum(dim=0) # db2 dim is (vocab_size), so it contributes 1 per column\n",
        "cmp('db2', db2, b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lFEMby-Anw1",
        "outputId": "4e62b6c9-936d-4d2c-8c1e-b98d10251afe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "db2             | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh = dlogits @ W2.T\n",
        "cmp('dh', dh, h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm2zyks5DHoI",
        "outputId": "09af2969-aa97-405d-afde-816e7c8b7b8a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh              | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 - backward of activation\n",
        "h = torch.tanh(h_preact)\n",
        "\n",
        "gradient of tanh(x) is 1-tanh(x)**2"
      ],
      "metadata": {
        "id": "c6mqXwa1Cozj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dh_preact = (1.0- h**2) * dh\n",
        "cmp('dh_preact', dh_preact, h_preact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDfxAkJdB6vF",
        "outputId": "1c7f38b3-e942-4a55-84e5-894eb025b739"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh_preact       | exact: False | approx: True  | maxdiff: 4.656612873077393e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h.grad.dtype"
      ],
      "metadata": {
        "id": "B0nctBjqiBwi",
        "outputId": "6ee15cef-dcf0-45cc-a5c9-925a6c4908ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4 - backward of Batch Norm layer"
      ],
      "metadata": {
        "id": "cXCha0D4Bg1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gamma, beta, x_hat\n",
        "h_preact = bn_gamma * x_hat + bn_bias"
      ],
      "metadata": {
        "id": "Bg3wclMqBrTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_gamma.shape, h_preact.shape, bn_bias.shape, x_hat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulzeOclHEmrt",
        "outputId": "96f1a3b4-5651-4360-e471-836423c14101"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 200]),\n",
              " torch.Size([32, 200]),\n",
              " torch.Size([1, 200]),\n",
              " torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_gamma = x_hat * dh_preact\n",
        "dbn_gamma = dbn_gamma.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_gamma', dbn_gamma, bn_gamma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKii5_L4EjM8",
        "outputId": "7321ae1f-b6e4-41b6-b240-c330ac0742bf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_gamma       | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_bias = dh_preact.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_bias', dbn_bias, bn_bias)"
      ],
      "metadata": {
        "id": "b6JGxUY37Y_k",
        "outputId": "3a777922-c8ed-4333-cc52-b281fbba89d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_bias        | exact: False | approx: True  | maxdiff: 3.725290298461914e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dx_hat = bn_gamma * dh_preact\n",
        "cmp('dx_hat', dx_hat, x_hat)"
      ],
      "metadata": {
        "id": "BcdaV1qA7pdF",
        "outputId": "9d539563-f01e-474a-c38a-f147ca6a36d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dx_hat          | exact: False | approx: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bn_varinv\n",
        "x_hat = bn_diff * bn_varinv"
      ],
      "metadata": {
        "id": "qze_SeQa78fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_hat.shape, bn_diff.shape, bn_varinv.shape"
      ],
      "metadata": {
        "id": "7Iftu-QA8UuB",
        "outputId": "9cd5799a-e947-444f-aa16-47c5fd625b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([32, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_varinv = bn_diff * dx_hat\n",
        "dbn_varinv = dbn_varinv.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_varinv', dbn_varinv, bn_varinv)"
      ],
      "metadata": {
        "id": "Oe6qNZPX8H7v",
        "outputId": "7492096f-3373-42c2-933b-ca46d0f100cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_varinv      | exact: False | approx: True  | maxdiff: 3.725290298461914e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bn_var\n",
        "bn_varinv = (bn_var + 1e-5)**-0.5"
      ],
      "metadata": {
        "id": "suf7fMhx8twK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_var.shape, bn_varinv.shape"
      ],
      "metadata": {
        "id": "14XrqYu79dMq",
        "outputId": "baf3a7fe-9622-4620-ead7-45b3d56c1c2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_var = -0.5 * ((bn_var+1e-5)**-1.5)\n",
        "dbn_var *= dbn_varinv\n",
        "cmp('dbn_var', dbn_var, bn_var)"
      ],
      "metadata": {
        "id": "L_M3uDSr80HT",
        "outputId": "c1087822-2eb1-4f4c-f871-2a4343b595a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_var         | exact: False | approx: True  | maxdiff: 6.984919309616089e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bn_diff2\n",
        "bn_var = 1/(batch_size-1) * bn_diff2.sum(dim=0, keepdim=True)"
      ],
      "metadata": {
        "id": "3ZzmSnsqC2_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_diff2.shape, dbn_var.shape"
      ],
      "metadata": {
        "id": "FQ4UDOPqDVPu",
        "outputId": "5c8fc8b4-e281-49b3-dea4-40dd10291c0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff2 = 1/(batch_size-1) * dbn_var\n",
        "dbn_diff2 = dbn_diff2.expand(bn_diff2.shape) # expand to the right shape\n",
        "\n",
        "# alternatively, the above can be done as\n",
        "#dbn_diff2 = 1/(batch_size-1) * torch.ones_like(bn_diff2) *dbn_var\n",
        "\n",
        "cmp('dbn_diff2', dbn_diff2, bn_diff2)\n",
        "#dbn_diff2"
      ],
      "metadata": {
        "id": "lhATtBVhC7b2",
        "outputId": "6fcd9b0d-1068-43a5-b259-bad80f58ea20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_diff2       | exact: False | approx: True  | maxdiff: 2.1827872842550278e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bn_diff\n",
        "bn_diff appears in 2 places: x_hat, bn_var, bn_diff2\n",
        "\n",
        "for x_hat:\n",
        "x_hat = bn_diff * bn_varinv\n",
        "\n",
        "for bn_diff2:\n",
        "bn_diff2 = bn_diff ** 2"
      ],
      "metadata": {
        "id": "3J4Ddi4eASxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff_1 = bn_varinv * dx_hat\n",
        "dbn_diff_2 = 2 * bn_diff * dbn_diff2\n",
        "dbn_diff = dbn_diff_1 + dbn_diff_2\n",
        "\n",
        "cmp('dbn_diff', dbn_diff, bn_diff)"
      ],
      "metadata": {
        "id": "mus6E5TbAg0-",
        "outputId": "c83576d9-e233-4ebe-e7da-444ccfc45fcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_diff        | exact: False | approx: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff.shape, bn_diff.shape"
      ],
      "metadata": {
        "id": "u42uW4SxJYIt",
        "outputId": "e4810f58-b01b-4b03-dd56-126a366108a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bn_mean\n",
        "bn_diff = (h_prebn - bn_mean)"
      ],
      "metadata": {
        "id": "K0E3PDM7GA7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_mean = -dbn_diff\n",
        "dbn_mean = dbn_mean.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_mean', dbn_mean, bn_mean)"
      ],
      "metadata": {
        "id": "-S8DEAYFHo0v",
        "outputId": "9c44dcc1-159d-4d01-fa17-ed6e86dcf530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_mean        | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff.shape, bn_mean.shape, dbn_mean.shape, bn_mean.grad.shape"
      ],
      "metadata": {
        "id": "lC8R-6XtoPF8",
        "outputId": "204c4c61-15c0-425e-96b2-020e65ca0487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]),\n",
              " torch.Size([1, 200]),\n",
              " torch.Size([1, 200]),\n",
              " torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###h_prebn\n",
        "h_prebn appears twice: once in bn_mean, once in bn_diff\n",
        "\n",
        "from bn_mean:\n",
        "bn_mean = 1/batch_size*h_prebn.sum(dim=0, keepdim=True)\n",
        "\n",
        "from bn_diff:\n",
        "bn_diff = (h_prebn - bn_mean)"
      ],
      "metadata": {
        "id": "sBShut01J1hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dh_prebn1 = dbn_diff.clone()\n",
        "dh_prebn2 = 1/batch_size * dbn_mean\n",
        "dh_prebn2 = dh_prebn2.expand(h_prebn.shape) # or can mult by torch.ones instead\n",
        "dh_prebn = dh_prebn1 + dh_prebn2\n",
        "cmp('dh_prebn', dh_prebn, h_prebn)"
      ],
      "metadata": {
        "id": "0TAzGbiJGHBu",
        "outputId": "ff567384-c274-4e4f-da65-4ccae08eba51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh_prebn        | exact: False | approx: True  | maxdiff: 6.984919309616089e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - backward of hidden layer\n",
        "h_prebn = embcat @ W1 + b1 # (batch_size, hidden_dim)"
      ],
      "metadata": {
        "id": "fl4dxf5GKjZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dW1 = embcat.T @ dh_prebn\n",
        "cmp('dW1', dW1, W1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezz7DoBMBo79",
        "outputId": "eb766fc0-a288-425d-b3e4-1e994ed5dc63"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dW1             | exact: False | approx: True  | maxdiff: 5.587935447692871e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dW1[0,:5], W1.grad[0,:5]"
      ],
      "metadata": {
        "id": "pW_9toJCMcVJ",
        "outputId": "e19e2b62-4552-468b-afae-01d91a197226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0002, -0.0157, -0.0017, -0.0064, -0.0011], grad_fn=<SliceBackward0>),\n",
              " tensor([ 0.0002, -0.0157, -0.0017, -0.0064, -0.0011]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dembcat = dh_prebn @ W1.T\n",
        "cmp('dembcat', dembcat, embcat)"
      ],
      "metadata": {
        "id": "b67a2202OXLm",
        "outputId": "5ab99eb8-fe2e-4dcd-acd6-dae1f28fc91e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dembcat         | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embcat.shape, W1.shape, h_prebn.shape"
      ],
      "metadata": {
        "id": "DWnaUimlOd_R",
        "outputId": "d3dff652-1cba-450b-f623-6287351bf555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 30]), torch.Size([30, 200]), torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db1 = torch.ones_like(b1) * dh_prebn\n",
        "db1 = db1.sum(dim=0)\n",
        "cmp('db1', db1, b1)"
      ],
      "metadata": {
        "id": "dGrFAT2lK6uF",
        "outputId": "6e756f82-2e1e-4c53-8ac3-9742513caf7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "db1             | exact: False | approx: True  | maxdiff: 6.51925802230835e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_prebn.shape, b1.shape, db1.shape, db1[:15], b1.grad[:15]"
      ],
      "metadata": {
        "id": "BU3etu1wKs31",
        "outputId": "30a11f4b-f036-459e-8502-fd6b6d3dc5b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]),\n",
              " torch.Size([200]),\n",
              " torch.Size([200]),\n",
              " tensor([ 2.9104e-10,  4.6566e-10, -4.6566e-10,  9.3132e-10,  0.0000e+00,\n",
              "          1.1642e-10,  4.6566e-10,  4.6566e-10,  0.0000e+00, -9.3132e-10,\n",
              "         -4.6566e-10,  0.0000e+00,  2.7940e-09, -5.8208e-10,  0.0000e+00],\n",
              "        grad_fn=<SliceBackward0>),\n",
              " tensor([ 4.6566e-10,  9.3132e-10,  0.0000e+00, -1.8626e-09,  9.3132e-10,\n",
              "          1.1642e-10,  4.6566e-10,  0.0000e+00,  0.0000e+00, -9.3132e-10,\n",
              "          0.0000e+00,  0.0000e+00,  1.0477e-09,  0.0000e+00,  0.0000e+00]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 - backward of embedding\n",
        "emb = C[xs] # (batch_size, block_size, hidden_dim)\n",
        "\n",
        "embcat = emb.view(emb.shape[0], -1)"
      ],
      "metadata": {
        "id": "Idz1PnXwNtBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C.shape, emb.shape, dembcat.shape, xs.shape"
      ],
      "metadata": {
        "id": "-dHhwLlmN8cO",
        "outputId": "0027bbd6-2d07-4677-b2d3-60fc77034930",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([27, 10]),\n",
              " torch.Size([32, 3, 10]),\n",
              " torch.Size([32, 30]),\n",
              " torch.Size([32, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demb = dembcat.view(emb.shape)\n",
        "cmp('demb', demb, emb)"
      ],
      "metadata": {
        "id": "aJgpmMOLPJz-",
        "outputId": "23902bb2-7175-4dae-e5da-93a8b658c526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "demb            | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dC = torch.zeros_like(C)\n",
        "# for i in range(xs.shape[0]):\n",
        "#   for j in range(xs.shape[1]):\n",
        "#     ix = xs[i,j]\n",
        "#     dC[ix] += demb[i,j]\n",
        "dC = torch.einsum('abc,abg->cg', F.one_hot(xs, vocab_size).float(), demb)\n",
        "cmp('dC', dC, C)"
      ],
      "metadata": {
        "id": "xHhhGkgpPXN-",
        "outputId": "2c0143e0-7fd3-4428-a68c-1b06ec1ca11c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dC              | exact: False | approx: True  | maxdiff: 1.1175870895385742e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[0], F.one_hot(xs, vocab_size)[0],F.one_hot(xs, vocab_size).shape"
      ],
      "metadata": {
        "id": "5OI8ljINJRcw",
        "outputId": "eb95503d-9f57-4ff8-f90e-f8689c937143",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 8,  1, 26]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0],\n",
              "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1]]),\n",
              " torch.Size([32, 3, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(F.one_hot(xs, vocab_size).view(xs.shape[0], -1));  # (32, 81)\n",
        "draw_grid = lambda x: plt.axvline(x=x, color='white', alpha=0.5);\n",
        "draw_grid(26)\n",
        "draw_grid(53)"
      ],
      "metadata": {
        "id": "_P9VZUxBJywC",
        "outputId": "67932252-5655-4212-877c-ef0b5990e643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7af67e061060>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2 - Fast loss\n",
        "This exercise uses the torch [cross_entropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) function as the loss in one step, then back prop the loss function in one go.\n",
        "\n",
        "From the pytorch man page:$L={\\{l_1, l_2, ..., l_N\\}}^{\\mathrm{T}}$\n",
        "$$l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
        "\\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
        "$$\n",
        "\n",
        "Translating into our naming in the python code:\n",
        "$$l_i = -log\\dfrac{\\exp(logits_{i, y_i})}{\\sum_{j}\\exp(logits_{i,j})}\n",
        "$$\n",
        "where $i\\in [0, batch\\_size), j\\in [0, vocab\\_size)$\n",
        "$$Loss = \\frac{1}{N}\\sum_{i}^{N}l_i$$\n",
        "\n",
        "Derivative: let's calculate $\\frac{\\delta l}{\\delta logits_j}$ and $\\frac{\\delta l}{\\delta logits_y}$, respectively. Let $s=logits$, for brievity.\n",
        "hence,\n",
        "$$l_i = -log\\dfrac{e^{s_{y_i}}}{\\sum_{j}e^{s_j}}\n",
        "$$\n",
        "## derivative\n",
        "see [my blog](https://romenlaw.blogspot.com/2024/06/study-notes-of-simple-neuro-network.html) for working:\n",
        "\n",
        "$$\\frac{\\delta l_i}{\\delta s_j} = P_i = softmax(s) \\\\\n",
        "\\frac{\\delta l_i}{\\delta s_y} = P_i-1 = softmax(s)-1 \\\\\n",
        "\\therefore \\frac{\\delta Loss}{\\delta s_j} = \\frac{1}{N}\\times P_i \\\\\n",
        "\\frac{\\delta Loss}{\\delta s_y} = \\frac{1}{N}\\times (P_i-1)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PblBFqmQGGUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fast = F.cross_entropy(logits, ys)\n",
        "print(loss_fast.item(), 'diff: ', (loss_fast - loss).item())"
      ],
      "metadata": {
        "id": "aCosFMbyGKyF",
        "outputId": "dee2780f-b905-4d53-f64a-bd41a53ef87d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5082900524139404 diff:  4.76837158203125e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dlogits = F.softmax(logits, dim=1)\n",
        "#dlogits[range(batch_size), ys] -= 1\n",
        "dlogits = F.softmax(logits, dim=1) - F.one_hot(ys, vocab_size)\n",
        "\n",
        "dlogits = dlogits / batch_size\n",
        "cmp('dlogits', dlogits, logits)"
      ],
      "metadata": {
        "id": "LrmDZ6k9sDhJ",
        "outputId": "82c41cb8-18ef-4937-cc44-ef35a66ca224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogits         | exact: False | approx: True  | maxdiff: 5.122274160385132e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(ys, vocab_size)[0], ys"
      ],
      "metadata": {
        "id": "QNJVgD7Z75S5",
        "outputId": "22995b01-228f-4208-8e8c-c7c986fa7c52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0]),\n",
              " tensor([12, 14,  8, 21,  8, 14, 12,  5,  9,  7,  3,  4,  5, 11,  5, 12,  9, 15,\n",
              "         15, 12, 16,  1,  0,  9, 15,  0,  1,  9, 15, 20,  5, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs=F.softmax(logits, 1)\n",
        "probs[0], probs[0].sum(), probs[0].max()"
      ],
      "metadata": {
        "id": "ZrfCpRDPV1sJ",
        "outputId": "a97b0db8-7b5d-4e26-9f35-df0022a94271",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0358, 0.0162, 0.0248, 0.0362, 0.0667, 0.0391, 0.0147, 0.1270, 0.0311,\n",
              "         0.0959, 0.0074, 0.0117, 0.0738, 0.0272, 0.0494, 0.0693, 0.0127, 0.0159,\n",
              "         0.0436, 0.0241, 0.0283, 0.0084, 0.0072, 0.0245, 0.0506, 0.0307, 0.0275],\n",
              "        grad_fn=<SelectBackward0>),\n",
              " tensor(1., grad_fn=<SumBackward0>),\n",
              " tensor(0.1270, grad_fn=<MaxBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits[0]*batch_size, dlogits[0].sum()"
      ],
      "metadata": {
        "id": "AjXl1idgV9X6",
        "outputId": "370b37ff-3cae-4c25-b390-0a462739ce9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0358,  0.0162,  0.0248,  0.0362,  0.0667,  0.0391,  0.0147,  0.1270,\n",
              "          0.0311,  0.0959,  0.0074,  0.0117, -0.9262,  0.0272,  0.0494,  0.0693,\n",
              "          0.0127,  0.0159,  0.0436,  0.0241,  0.0283,  0.0084,  0.0072,  0.0245,\n",
              "          0.0506,  0.0307,  0.0275], grad_fn=<MulBackward0>),\n",
              " tensor(-1.3970e-09, grad_fn=<SumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,6))\n",
        "ax1.imshow((dlogits*batch_size).detach(), cmap='gray')\n",
        "#ax1.colorbar()\n",
        "ax2.imshow((probs).detach(), cmap='gray')\n",
        "#ax2.colorbar()"
      ],
      "metadata": {
        "id": "XXQL1em5VEKt",
        "outputId": "c38c887d-3cf3-4034-9c7f-2c66cc01dffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7af670b6bc10>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "makemore_backprop.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}