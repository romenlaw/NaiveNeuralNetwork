{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romenlaw/NaiveNeuralNetwork/blob/main/makemore_backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4f4JG1gdKqj"
      },
      "source": [
        "#Makemore - backprop ninja"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare datasets"
      ],
      "metadata": {
        "id": "vTLLwG6T_Srt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/romenlaw/NaiveNeuralNetwork/main/names.txt"
      ],
      "metadata": {
        "id": "WnJ_g9N870O8",
        "outputId": "378889e1-430d-4e20-8292-c691d6623bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  222k  100  222k    0     0   996k      0 --:--:-- --:--:-- --:--:--  999k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "kI-rQ1qpCWoV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "len(words), max(len(w) for w in words), words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RRwKoRN_V0p",
        "outputId": "7e027e5e-b8e5-4320-bc6e-711d09a5fe00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32033,\n",
              " 15,\n",
              " ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(list(set(''.join(words))))\n",
        "vocab.insert(0, '.')\n",
        "itos = { i:s for i,s in enumerate(vocab)}\n",
        "stoi = { s:i for i,s in enumerate(vocab)}\n",
        "vocab_size = len(vocab)  # 27"
      ],
      "metadata": {
        "id": "rWeh-qTNAOxO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 3  # context size - 3 tokens\n",
        "\n",
        "def build_dataset(words):\n",
        "  \"\"\"returns torch tensors X, Y where\n",
        "  X is a list of n-grams indices covering the whole words list, where n=block_size\n",
        "  Y is a list of indices predicting each n-gram in X\n",
        "  \"\"\"\n",
        "  X, Y = [], []\n",
        "\n",
        "  #for w in words[:5]:\n",
        "  for w in words:\n",
        "    context = [0] * block_size # repeat '.' to fill block_size\n",
        "    for ch in w+'.':\n",
        "      ix = stoi[ch]\n",
        "      #print(' '.join([itos[i] for i in context]), '---->', itos[ix])\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix]\n",
        "\n",
        "  return torch.tensor(X), torch.tensor(Y)\n",
        "\n",
        "X, Y = build_dataset(words)\n",
        "#X[:32], Y[:32]\n",
        "\n",
        "# split the data into 3 sets\n",
        "# 80% for training set\n",
        "# 10% for validation/development\n",
        "# 10% for testing\n",
        "import random\n",
        "random.seed(42)\n",
        "n1 = int(len(words) * .8)\n",
        "n2 = int(len(words) * .9)\n",
        "random.shuffle(words) # shuffle is in-place\n",
        "X_train, Y_train = build_dataset(words[:n1])\n",
        "X_dev, Y_dev = build_dataset(words[n1:n2])\n",
        "X_test, Y_test = build_dataset(words[n2:])\n",
        "\n",
        "#len(words[n1:n2])\n",
        "(X_train.shape, Y_train.shape), (X_dev.shape, Y_dev.shape), (X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_wuMWU1BUFe",
        "outputId": "12478339-9a63-4b89-ec73-69040d8ddf6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((torch.Size([182625, 3]), torch.Size([182625])),\n",
              " (torch.Size([22655, 3]), torch.Size([22655])),\n",
              " (torch.Size([22866, 3]), torch.Size([22866])))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## utilities"
      ],
      "metadata": {
        "id": "_Zrl2yoKDHSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utility to compare our manual gradients with pytorch gradients\n",
        "def cmp(s, dt, t):\n",
        "  \"\"\"Compares dt and t.grad to see if their values are equal or close\n",
        "  s - name of the parameter being compared, used in printing only\n",
        "  dt - tensor of manually calculated gradient\n",
        "  t - torch tensor\n",
        "  \"\"\"\n",
        "  ex = torch.all(dt==t.grad).item()\n",
        "  apx = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approx: {str(apx):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "x9d-letYDPF7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP\n",
        "In the parameter initialisation, we use non-standard values to see their effect; otherwise, for example, zeros can mask out any incorrect values."
      ],
      "metadata": {
        "id": "VAOQhg9HNNyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 10\n",
        "hidden_dim = 200\n",
        "\n",
        "g = torch.Generator().manual_seed(20240824)\n",
        "C = torch.randn((vocab_size, embed_dim),  generator=g)\n",
        "\n",
        "# hidden layer\n",
        "fan_in = embed_dim*block_size # we concat multiple C's to feed into hidden layer\n",
        "W1 = torch.randn((fan_in, hidden_dim), generator=g) * (5/3 / fan_in**0.5)\n",
        "b1 = torch.randn(hidden_dim,           generator=g) * 0.1 # experiment\n",
        "# output layer\n",
        "W2 = torch.randn((hidden_dim, vocab_size), generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,               generator=g) * 0.1 # experiment with non-zero\n",
        "\n",
        "# batch normalisation 1D layer placed after hidden layer, hence dim=hidden_dim\n",
        "bn_gamma = torch.randn((1, hidden_dim),    generator=g) * 0.1 + 1.0\n",
        "bn_bias = torch.randn((1, hidden_dim),     generator=g) * 0.1\n",
        "\n",
        "# the above are initialised with non-standard values to magnify any incorrect values\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bn_gamma, bn_bias]\n",
        "print('total params: ', sum([p.nelement() for p in parameters]))\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4EIrTkZNPpo",
        "outputId": "ba935d3e-009d-46d5-d833-e7f1746c99c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total params:  12297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1 - slow pass\n",
        "This exercise breaks down the forward pass into atomic individual steps, then back prop each step."
      ],
      "metadata": {
        "id": "ndKNtGStGcgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training - extended version\n",
        "We expand the forward pass into step by step calculations so that we can manually calculate the gradient step by step as well. For Cross Entropy loss function, see [pyTorch doco](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss).\n",
        "\n",
        "We don't call the loss.backward(). Instead, we will do it manually."
      ],
      "metadata": {
        "id": "T9c-gp2PM-Rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# understanding tensor.values, which only works on sparse tensor\n",
        "t = torch.randn((2,3))\n",
        "sparse_tensor = t.max(dim=1, keepdim=True)\n",
        "t, '-----------', sparse_tensor, '------------', sparse_tensor.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4UqInlQLqw4",
        "outputId": "8af2e7a5-c85d-4aad-ab56-b5a99d38a12c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-2.7579, -0.3532,  0.5664],\n",
              "         [-0.1045,  0.6642, -0.6702]]),\n",
              " '-----------',\n",
              " torch.return_types.max(\n",
              " values=tensor([[0.5664],\n",
              "         [0.6642]]),\n",
              " indices=tensor([[2],\n",
              "         [1]])),\n",
              " '------------',\n",
              " tensor([[0.5664],\n",
              "         [0.6642]]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# construct mini-batch:\n",
        "# generate a list of random indices, length of list if batch_size\n",
        "ix = torch.randint(low=0, high=X_train.shape[0], size=(batch_size,), generator=g)\n",
        "xs = X_train[ix]  # (batch_size, block_size)\n",
        "ys = Y_train[ix]  # (batch_size)\n",
        "\n",
        "##################################\n",
        "# forward pass (expanded version)\n",
        "##################################\n",
        "# embedding ---------------------------\n",
        "emb = C[xs] # (batch_size, block_size, hidden_dim)\n",
        "embcat = emb.view(emb.shape[0], -1)\n",
        "# hidden layer ------------------------\n",
        "h_prebn = embcat @ W1 + b1 # (batch_size, hidden_dim)\n",
        "# BN layer (expended version) ----------------------------\n",
        "#bn_mean = h_prebn.mean(dim=0, keepdim=True)\n",
        "bn_mean = 1/batch_size*h_prebn.sum(dim=0, keepdim=True)\n",
        "#bn_std = h_prebn.std(dim=0, keepdim=True)\n",
        "bn_diff = (h_prebn - bn_mean)\n",
        "bn_diff2 = bn_diff ** 2\n",
        "bn_var = 1/(batch_size-1) * bn_diff2.sum(dim=0, keepdim=True) # Bessel's correction, divide by m-1 not m\n",
        "bn_varinv = (bn_var + 1e-5)**-0.5  # 1/sqrt(var+eps)\n",
        "x_hat = bn_diff * bn_varinv\n",
        "h_preact = bn_gamma * x_hat + bn_bias\n",
        "# Non-linearity ----------------------\n",
        "h = torch.tanh(h_preact)  # (batch_size, hidden_dim)\n",
        "# output layer -----------------------\n",
        "logits = h @ W2 + b2 # (hidden_dim, vocab_size)\n",
        "# loss function (extended version) ----------------------\n",
        "#loss = F.cross_entropy(logits, ys)\n",
        "logit_maxes = logits.max(dim=1, keepdim=True).values  # (hidden_dim, 1)\n",
        "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "counts = norm_logits.exp()  # (batch_size, vocab_size)\n",
        "counts_sum = counts.sum(dim=1, keepdim=True) # (batch_size, 1)\n",
        "counts_sum_inv = counts_sum ** -1  # (batch_size, 1)\n",
        "probs = counts * counts_sum_inv  # (batch_size, vocab_size)\n",
        "logprobs = probs.log()   # (batch_size, vocab_size)\n",
        "loss = -logprobs[range(batch_size), ys].mean()  # scalar\n",
        "\n",
        "################\n",
        "# backward pass\n",
        "################\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts_sum_inv, counts_sum, counts,\n",
        "          norm_logits, logit_maxes, logits,\n",
        "          h, h_preact, x_hat, bn_varinv, bn_var, bn_diff2, bn_diff, bn_mean,\n",
        "          h_prebn, embcat, emb ]:\n",
        "  t.retain_grad()\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('loss: %2.10f' % (loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOpGCG2TNAkI",
        "outputId": "b6ac46d3-bd0e-4eee-8266-59e4dc22fe3f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 3.5082895756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb19DCBUFD3W",
        "outputId": "5a3f57da-d485-4389-8bf9-5130ff934512"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - backward pass of loss function"
      ],
      "metadata": {
        "id": "ry8Xbe9-DPNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dlogprobs\n",
        "logprobs is dimension (N, vocab_size) , where N = batch_size\n",
        "$$loss = -\\dfrac{1}{N}\\sum_{i=1}^{N}logprobs_{i, y_i}$$\n",
        "For the loss function, only elements at indices $[i, y_i]$ contribute to the loss. The rest are not used. Therefore, the unused elements have gradient 0.\n",
        "$$\\dfrac{\\delta loss}{\\delta logprobs}=\n",
        "\\begin{cases}\n",
        "-\\dfrac{1}{N} & \\quad \\text{at positions }{i},{y_i}\\\\\n",
        "0 & \\quad \\text{elsewhere}\n",
        "\\end{cases}\n",
        "$$"
      ],
      "metadata": {
        "id": "zcMTxreLHKO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(batch_size), ys] = -1/batch_size\n",
        "cmp('dlogprobs', dlogprobs, logprobs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek7Mmk4fO9kt",
        "outputId": "6cb26e13-a5b7-4500-a8c1-c0194f9ae115"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogprobs       | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dprobs\n",
        "$$logprobs = \\ln(probs)$$\n",
        "$$\\dfrac{\\delta logprobs}{\\delta probs} = \\dfrac{1}{probs}\n",
        "$$"
      ],
      "metadata": {
        "id": "i_6hGt3IJduM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dprobs = 1/probs * dlogprobs\n",
        "cmp('dprobs', dprobs, probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZAWM-h4T_3y",
        "outputId": "11578dd8-e9c0-43ea-a8b8-a14e13ce616f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dprobs          | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dcount_sum_inv\n",
        "\n",
        "$$probs = counts * \\text{counts_sum_inv}\n",
        "$$\n",
        "$$\\dfrac{\\delta probs}{\\delta \\text{counts_sum_inv}} = counts\n",
        "$$\n",
        "Note that the dimension of counts_sum_inv is (N, 1), so does its derivative."
      ],
      "metadata": {
        "id": "ocS5fuREeaw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum_inv = counts * dprobs\n",
        "dcounts_sum_inv = dcounts_sum_inv.sum(dim=1, keepdim=True)\n",
        "cmp('dcounts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUwrnaS7KURu",
        "outputId": "d017a458-e3e4-429b-c390-c091db69ab38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcounts_sum_inv | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dcounts_sum\n",
        "$$\\text{counts_sum_inv} = \\text{counts_sum}^{-1}\n",
        "$$\n",
        "$$\\dfrac{\\delta\\text{counts_sum_inv}}{\\delta\\text{counts_sum}} = -\\text{counts_sum}^{-2}\n",
        "$$"
      ],
      "metadata": {
        "id": "91_4MFMKh1aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum=-counts_sum**-2\n",
        "dcounts_sum *= dcounts_sum_inv\n",
        "cmp('dcounts_sum', dcounts_sum, counts_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2VR1zGJKonc",
        "outputId": "e53f9de8-4b11-4e84-d67b-33c3e30950ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcounts_sum     | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts_sum[0], counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY4dWJRcvU8T",
        "outputId": "f47815a5-151a-4168-b8c8-30f8b5f4656f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0040], grad_fn=<SelectBackward0>), torch.Size([32, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dcounts\n",
        "counts is used twice in the forward pass: once in counts_sum, another in probs.\n",
        "for counts_sum:\n",
        "$$\\text{counts_sum} = \\sum_{j=1}^{\\text{vocab_size}}counts_{i,j}\n",
        "$$\n",
        "$$\\dfrac{\\delta \\text{counts_sum}}{\\delta counts} = 1_{N, \\text{vocab_size}}\n",
        "$$\n",
        "Note that the 1 is same dimension as counts, i.e. (N, vocab_size)\n",
        "\n",
        "For probs:\n",
        "$$probs = counts * \\text{counts_sum_inv}\n",
        "$$\n",
        "$$\\dfrac{\\delta probs}{\\delta counts} = \\text{counts_sum_inv}\n",
        "$$"
      ],
      "metadata": {
        "id": "68bhFVV7i2n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts1 = torch.ones_like(counts) * dcounts_sum\n",
        "dcounts2 = counts_sum_inv * dprobs\n",
        "dcounts = dcounts1 + dcounts2\n",
        "cmp('dcounts', dcounts, counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y8HNLAhLnl9",
        "outputId": "65de08f7-eb4f-4489-e9d8-68c3f5e5ba29"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dcounts         | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dnorm_logits\n",
        "$$counts = e^{\\text{norm_logits}}\n",
        "$$\n",
        "$$\\dfrac{\\delta counts}{\\delta \\text{norm_logits}} = e^{\\text{norm_logits}}\n",
        "$$"
      ],
      "metadata": {
        "id": "uuwxEfgywi2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dnorm_logits = counts * dcounts\n",
        "cmp('dnorm_logits', dnorm_logits, norm_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVKWhVSRwlZo",
        "outputId": "da59a5c4-d24e-4bb1-9646-1512e813789a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dnorm_logits    | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZkwOMb_4hG7",
        "outputId": "e00070e5-c1dc-493e-c760-725225d9feda"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dlogit_maxes\n",
        "$$\\text{norm_logits}=logits_i - \\text{logit_maxes}_i \\quad \\text{for }i \\in [0,N)\n",
        "$$\n",
        "The dimension of logit_maxes is (N,1)\n",
        "\n",
        "$$\\dfrac{\\delta \\text{norm_logits}}{\\delta \\text{logit_maxes}} = -\\sum_{j}^{\\text{vocab_size}}1\n",
        "$$"
      ],
      "metadata": {
        "id": "QR5zcUsMypVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogit_maxes = -dnorm_logits\n",
        "dlogit_maxes = dlogit_maxes.sum(dim=1, keepdim=True)\n",
        "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s6uXNI_0-4l",
        "outputId": "23ea0b64-00e2-4730-ead9-7de55bca50ce"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogit_maxes    | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit_maxes.shape, dlogit_maxes.shape, logit_maxes.grad[0], dlogit_maxes[0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htjF-XEF4Ac9",
        "outputId": "25c10169-14e0-4cf7-be18-03f9fad22eae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1]),\n",
              " torch.Size([32, 1]),\n",
              " tensor([-3.7253e-09]),\n",
              " tensor(-3.7253e-09, grad_fn=<SumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dlogits\n",
        "logits are used twice in forward pass, once in norm_logits, once in logit_maxes.\n",
        "\n",
        "For norm_logits:\n",
        "$$\\text{norm_logits}=logits - \\text{logit_maxes}\n",
        "$$\n",
        "$$\\dfrac{\\delta \\text{norm_logits}}{\\delta logits} = 1\n",
        "$$\n",
        "\n",
        "For logit_maxes:\n",
        "$$\\text{logit_maxes}=max(logits_j)  \\quad \\text{for }j \\in [0, \\text{vocab_size})\n",
        "$$\n",
        "Therefore, for each row, only the max value index contributes to the gradient, the rest of the gradient is zero.\n",
        "$$\\dfrac{\\delta \\text{logit_maxes}}{\\delta logits}=\n",
        "\\begin{cases}\n",
        "1 & \\quad \\text{when }logits_j \\text{ is the max of the sample}\\\\\n",
        "0 & \\quad \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "6MUADJr1xu8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits1 = dnorm_logits\n",
        "\n",
        "##dlogits2 = torch.zeros_like(logits)\n",
        "##dlogits2[range(logits.shape[0]), torch.argmax(logits, dim=1)]=1\n",
        "# alternatively, the above can be done as\n",
        "#dlogits2[range(logits.shape[0]), logits.max(dim=1).indices] =1\n",
        "##dlogits2 *= dlogit_maxes\n",
        "\n",
        "# alternatively, the above can be done as one-hot\n",
        "dlogits2 = F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
        "\n",
        "dlogits = dlogits1 + dlogits2\n",
        "cmp('dlogits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUlyIz-Hx1eK",
        "outputId": "457fb745-b6ac-42c4-ca32-e19a91174b04"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogits         | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "FQezDYzoYAUC",
        "outputId": "32b640f6-eb59-4e38-9eb8-7166f0000941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7, 14,  4,  8, 21, 13, 22, 24, 13, 22, 22, 22,  8, 18, 22, 22, 24, 25,\n",
              "        19,  5, 15,  2,  2,  7, 25,  9, 17, 24, 21, 24,  9, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits2[range(logits.shape[0]), torch.argmax(logits, dim=1)]=1\n",
        "dlogits2"
      ],
      "metadata": {
        "id": "znx4r9VIWUwm",
        "outputId": "00cfdc7c-1e23-4378-9e53-ad0c7ddf1b79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., 1., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., 1., -0., -0., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., 1., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         1., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., 1., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [-0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [-0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., 1., -0., -0.],\n",
              "        [-0., -0., -0., -0., -0., -0., -0., -0., -0., 1., -0., -0., -0., -0., -0., -0., -0., -0.,\n",
              "         -0., -0., -0., -0., -0., -0., -0., -0., -0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<IndexPutBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits.max(dim=1).indices"
      ],
      "metadata": {
        "id": "ymrktLq6YFf_",
        "outputId": "08f4e5e7-d359-4d05-bdcf-e46196a182cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7, 14,  4,  8, 21, 13, 22, 24, 13, 22, 22, 22,  8, 18, 22, 22, 24, 25,\n",
              "        19,  5, 15,  2,  2,  7, 25,  9, 17, 24, 21, 24,  9, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits2 = torch.zeros_like(logits)\n",
        "dlogits2[range(logits.shape[0]), logits.max(dim=1).indices] =1\n",
        "dlogits2"
      ],
      "metadata": {
        "id": "EhvAxLr_Xr5l",
        "outputId": "3fbdab0b-3ab5-40f4-ba43-cc4699eba5cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(logits.max(1).indices, num_classes=logits.shape[1])"
      ],
      "metadata": {
        "id": "RwxIKICNaFCA",
        "outputId": "09f78623-cba8-438e-fa05-9c8c4ea6a0cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 - backward of output layer"
      ],
      "metadata": {
        "id": "QcBnehFN-93U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "logits = h @ W2 + b2\n",
        "\n",
        "manipulate to match the dimensions."
      ],
      "metadata": {
        "id": "ur-q2bec_Igd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2.shape, dlogits.shape, h.shape, b2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tawsmCSC_jRe",
        "outputId": "23602494-bcf4-4dd8-bd24-4deaf852cb5a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([200, 27]),\n",
              " torch.Size([32, 27]),\n",
              " torch.Size([32, 200]),\n",
              " torch.Size([27]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dW2 = h.T @ dlogits\n",
        "cmp('dW2', dW2, W2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqihgwvy_BjP",
        "outputId": "501e7c78-0afa-4458-8f82-9ad086bf3353"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dW2             | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#db2 = torch.ones_like(b2) * dlogits\n",
        "db2 = dlogits.sum(dim=0) # db2 dim is (vocab_size), so it contributes 1 per column\n",
        "cmp('db2', db2, b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lFEMby-Anw1",
        "outputId": "759a5d18-b022-40ad-932a-fcb5cdcc9e39"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "db2             | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh = dlogits @ W2.T\n",
        "cmp('dh', dh, h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm2zyks5DHoI",
        "outputId": "4ea2bd0e-946b-4f05-9b05-07814893491c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh              | exact: True  | approx: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 - backward of activation\n",
        "h = torch.tanh(h_preact)\n",
        "\n",
        "gradient of tanh(x) is 1-tanh(x)**2"
      ],
      "metadata": {
        "id": "c6mqXwa1Cozj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dh_preact = (1.0- h**2) * dh\n",
        "cmp('dh_preact', dh_preact, h_preact)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDfxAkJdB6vF",
        "outputId": "425b1d98-c45f-4c6c-99f1-a7d92595e733"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh_preact       | exact: False | approx: True  | maxdiff: 4.656612873077393e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h.grad.dtype"
      ],
      "metadata": {
        "id": "B0nctBjqiBwi",
        "outputId": "1c5f52cd-d4ff-47a6-ce1d-d468d3845696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4 - backward of Batch Norm layer"
      ],
      "metadata": {
        "id": "cXCha0D4Bg1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gamma, beta, x_hat\n",
        "h_preact = bn_gamma * x_hat + bn_bias"
      ],
      "metadata": {
        "id": "Bg3wclMqBrTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_gamma.shape, h_preact.shape, bn_bias.shape, x_hat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulzeOclHEmrt",
        "outputId": "4ce3d35e-76da-40bc-aa15-c6656a971f81"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 200]),\n",
              " torch.Size([32, 200]),\n",
              " torch.Size([1, 200]),\n",
              " torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_gamma = x_hat * dh_preact\n",
        "dbn_gamma = dbn_gamma.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_gamma', dbn_gamma, bn_gamma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKii5_L4EjM8",
        "outputId": "1740e6d2-f54b-43e4-ad8f-50c6a2ecf75c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_gamma       | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_bias = dh_preact.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_bias', dbn_bias, bn_bias)"
      ],
      "metadata": {
        "id": "b6JGxUY37Y_k",
        "outputId": "a4e4ceaa-b35a-47de-b0ef-4615073011f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_bias        | exact: False | approx: True  | maxdiff: 3.725290298461914e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dx_hat = bn_gamma * dh_preact\n",
        "cmp('dx_hat', dx_hat, x_hat)"
      ],
      "metadata": {
        "id": "BcdaV1qA7pdF",
        "outputId": "3131a030-94ee-4653-eacb-e64a8dbacb50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dx_hat          | exact: False | approx: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bn_varinv\n",
        "x_hat = bn_diff * bn_varinv"
      ],
      "metadata": {
        "id": "qze_SeQa78fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_hat.shape, bn_diff.shape, bn_varinv.shape"
      ],
      "metadata": {
        "id": "7Iftu-QA8UuB",
        "outputId": "6b7ff1a3-d4fd-4ca6-f53f-31bfd37d7c1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([32, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_varinv = bn_diff * dx_hat\n",
        "dbn_varinv = dbn_varinv.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_varinv', dbn_varinv, bn_varinv)"
      ],
      "metadata": {
        "id": "Oe6qNZPX8H7v",
        "outputId": "4a92e504-38ce-4153-e9ef-ad7727ecdaa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_varinv      | exact: False | approx: True  | maxdiff: 3.725290298461914e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bn_var\n",
        "bn_varinv = (bn_var + 1e-5)**-0.5"
      ],
      "metadata": {
        "id": "suf7fMhx8twK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_var.shape, bn_varinv.shape"
      ],
      "metadata": {
        "id": "14XrqYu79dMq",
        "outputId": "9391647f-91d5-4854-e129-86fa1192cf08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_var = -0.5 * ((bn_var+1e-5)**-1.5)\n",
        "dbn_var *= dbn_varinv\n",
        "cmp('dbn_var', dbn_var, bn_var)"
      ],
      "metadata": {
        "id": "L_M3uDSr80HT",
        "outputId": "8c1951b8-2224-463d-f383-34dbb103c6fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_var         | exact: False | approx: True  | maxdiff: 6.984919309616089e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bn_diff2\n",
        "bn_var = 1/(batch_size-1) * bn_diff2.sum(dim=0, keepdim=True)"
      ],
      "metadata": {
        "id": "3ZzmSnsqC2_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bn_diff2.shape, dbn_var.shape"
      ],
      "metadata": {
        "id": "FQ4UDOPqDVPu",
        "outputId": "6bc1c51a-8d96-46e4-f5d5-4c92ede5cd60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff2 = 1/(batch_size-1) * dbn_var\n",
        "dbn_diff2 = dbn_diff2.expand(bn_diff2.shape) # expand to the right shape\n",
        "\n",
        "# alternatively, the above can be done as\n",
        "#dbn_diff2 = 1/(batch_size-1) * torch.ones_like(bn_diff2) *dbn_var\n",
        "\n",
        "cmp('dbn_diff2', dbn_diff2, bn_diff2)\n",
        "#dbn_diff2"
      ],
      "metadata": {
        "id": "lhATtBVhC7b2",
        "outputId": "9c862147-cf6b-46c7-caad-c7340557450e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_diff2       | exact: False | approx: True  | maxdiff: 2.1827872842550278e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###bn_diff\n",
        "bn_diff appears in 2 places: x_hat, bn_var, bn_diff2\n",
        "\n",
        "for x_hat:\n",
        "x_hat = bn_diff * bn_varinv\n",
        "\n",
        "for bn_diff2:\n",
        "bn_diff2 = bn_diff ** 2"
      ],
      "metadata": {
        "id": "3J4Ddi4eASxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff_1 = bn_varinv * dx_hat\n",
        "dbn_diff_2 = 2 * bn_diff * dbn_diff2\n",
        "dbn_diff = dbn_diff_1 + dbn_diff_2\n",
        "\n",
        "cmp('dbn_diff', dbn_diff, bn_diff)"
      ],
      "metadata": {
        "id": "mus6E5TbAg0-",
        "outputId": "47e7f80a-9de7-4007-dabe-a34a6d4a3347",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_diff        | exact: False | approx: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff.shape, bn_diff.shape"
      ],
      "metadata": {
        "id": "u42uW4SxJYIt",
        "outputId": "55f96361-090b-4447-b9c0-0c26b4b935e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]), torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bn_mean\n",
        "bn_diff = (h_prebn - bn_mean)"
      ],
      "metadata": {
        "id": "K0E3PDM7GA7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_mean = -dbn_diff\n",
        "dbn_mean = dbn_mean.sum(dim=0, keepdim=True)\n",
        "cmp('dbn_mean', dbn_mean, bn_mean)"
      ],
      "metadata": {
        "id": "-S8DEAYFHo0v",
        "outputId": "56bfe0a6-16ea-46d5-865e-84ab07326313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dbn_mean        | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dbn_diff.shape, bn_mean.shape, dbn_mean.shape, bn_mean.grad.shape"
      ],
      "metadata": {
        "id": "lC8R-6XtoPF8",
        "outputId": "92a67f93-3465-4944-d2ea-d025e503e728",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]),\n",
              " torch.Size([1, 200]),\n",
              " torch.Size([1, 200]),\n",
              " torch.Size([1, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###h_prebn\n",
        "h_prebn appears twice: once in bn_mean, once in bn_diff\n",
        "\n",
        "from bn_mean:\n",
        "bn_mean = 1/batch_size*h_prebn.sum(dim=0, keepdim=True)\n",
        "\n",
        "from bn_diff:\n",
        "bn_diff = (h_prebn - bn_mean)"
      ],
      "metadata": {
        "id": "sBShut01J1hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dh_prebn1 = dbn_diff.clone()\n",
        "dh_prebn2 = 1/batch_size * dbn_mean\n",
        "dh_prebn2 = dh_prebn2.expand(h_prebn.shape) # or can mult by torch.ones instead\n",
        "dh_prebn = dh_prebn1 + dh_prebn2\n",
        "cmp('dh_prebn', dh_prebn, h_prebn)"
      ],
      "metadata": {
        "id": "0TAzGbiJGHBu",
        "outputId": "5019788e-8897-4b2d-ef0e-8fffc513529a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh_prebn        | exact: False | approx: True  | maxdiff: 6.984919309616089e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - backward of hidden layer\n",
        "h_prebn = embcat @ W1 + b1 # (batch_size, hidden_dim)"
      ],
      "metadata": {
        "id": "fl4dxf5GKjZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dW1 = embcat.T @ dh_prebn\n",
        "cmp('dW1', dW1, W1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezz7DoBMBo79",
        "outputId": "4a3d025a-b919-4d6f-e926-df3f2d63513c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dW1             | exact: False | approx: True  | maxdiff: 5.587935447692871e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dW1[0,:5], W1.grad[0,:5]"
      ],
      "metadata": {
        "id": "pW_9toJCMcVJ",
        "outputId": "a81ee623-fabf-419d-94c8-fbe779b0668f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0002, -0.0157, -0.0017, -0.0064, -0.0011], grad_fn=<SliceBackward0>),\n",
              " tensor([ 0.0002, -0.0157, -0.0017, -0.0064, -0.0011]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dembcat = dh_prebn @ W1.T\n",
        "cmp('dembcat', dembcat, embcat)"
      ],
      "metadata": {
        "id": "b67a2202OXLm",
        "outputId": "eb424164-f53f-4c30-da60-b23e92eb2ac7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dembcat         | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embcat.shape, W1.shape, h_prebn.shape"
      ],
      "metadata": {
        "id": "DWnaUimlOd_R",
        "outputId": "60137f01-4ebc-43d3-b305-05e374978f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 30]), torch.Size([30, 200]), torch.Size([32, 200]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db1 = dh_prebn.sum(dim=0)\n",
        "cmp('db1', db1, b1)"
      ],
      "metadata": {
        "id": "dGrFAT2lK6uF",
        "outputId": "5f9c0b67-20b3-485a-fdc8-df3eaa8fc627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "db1             | exact: False | approx: True  | maxdiff: 6.51925802230835e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h_prebn.shape, b1.shape, db1.shape, db1[:15], b1.grad[:15]"
      ],
      "metadata": {
        "id": "BU3etu1wKs31",
        "outputId": "cea5e70d-4ae0-41cf-fe26-4afe86a16537",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 200]),\n",
              " torch.Size([200]),\n",
              " torch.Size([200]),\n",
              " tensor([ 2.9104e-10,  4.6566e-10, -4.6566e-10,  9.3132e-10,  0.0000e+00,\n",
              "          1.1642e-10,  4.6566e-10,  4.6566e-10,  0.0000e+00, -9.3132e-10,\n",
              "         -4.6566e-10,  0.0000e+00,  2.7940e-09, -5.8208e-10,  0.0000e+00],\n",
              "        grad_fn=<SliceBackward0>),\n",
              " tensor([ 4.6566e-10,  9.3132e-10,  0.0000e+00, -1.8626e-09,  9.3132e-10,\n",
              "          1.1642e-10,  4.6566e-10,  0.0000e+00,  0.0000e+00, -9.3132e-10,\n",
              "          0.0000e+00,  0.0000e+00,  1.0477e-09,  0.0000e+00,  0.0000e+00]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 - backward of embedding\n",
        "emb = C[xs] # (batch_size, block_size, hidden_dim)\n",
        "\n",
        "embcat = emb.view(emb.shape[0], -1)"
      ],
      "metadata": {
        "id": "Idz1PnXwNtBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C.shape, emb.shape, dembcat.shape, xs.shape"
      ],
      "metadata": {
        "id": "-dHhwLlmN8cO",
        "outputId": "113ee4ca-7049-4ca8-db02-d121f6221c17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([27, 10]),\n",
              " torch.Size([32, 3, 10]),\n",
              " torch.Size([32, 30]),\n",
              " torch.Size([32, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demb = dembcat.view(emb.shape)\n",
        "cmp('demb', demb, emb)"
      ],
      "metadata": {
        "id": "aJgpmMOLPJz-",
        "outputId": "cac76885-9816-4fa3-a458-3c60f5ca8578",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "demb            | exact: False | approx: True  | maxdiff: 2.7939677238464355e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dC = torch.zeros_like(C)\n",
        "# for i in range(xs.shape[0]):\n",
        "#   for j in range(xs.shape[1]):\n",
        "#     ix = xs[i,j]\n",
        "#     dC[ix] += demb[i,j]\n",
        "dC = torch.einsum('abc,abg->cg', F.one_hot(xs, vocab_size).float(), demb)\n",
        "cmp('dC', dC, C)"
      ],
      "metadata": {
        "id": "xHhhGkgpPXN-",
        "outputId": "c59b9ce1-e634-4788-9cd8-3a9de901cb58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dC              | exact: False | approx: True  | maxdiff: 1.1175870895385742e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[0], F.one_hot(xs, vocab_size)[0],F.one_hot(xs, vocab_size).shape"
      ],
      "metadata": {
        "id": "5OI8ljINJRcw",
        "outputId": "ec6888db-fa0a-42c0-b0af-e9889db5eca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 8,  1, 26]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0],\n",
              "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1]]),\n",
              " torch.Size([32, 3, 27]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(F.one_hot(xs, vocab_size).view(xs.shape[0], -1));  # (32, 81)\n",
        "draw_grid = lambda x: plt.axvline(x=x, color='white', alpha=0.5);\n",
        "draw_grid(26)\n",
        "draw_grid(53)"
      ],
      "metadata": {
        "id": "_P9VZUxBJywC",
        "outputId": "bd725502-8840-40f4-a42a-449d8e388cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7fac5a752ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2 - Fast loss\n",
        "This exercise uses the torch [cross_entropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) function as the loss in one step, then back prop the loss function in one go.\n",
        "\n",
        "From the pytorch man page:$L={\\{l_1, l_2, ..., l_N\\}}^{\\mathrm{T}}$\n",
        "$$l_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n",
        "\\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\n",
        "$$\n",
        "\n",
        "Translating into our naming in the python code:\n",
        "$$l_i = -log\\dfrac{\\exp(logits_{i, y_i})}{\\sum_{j}\\exp(logits_{i,j})}\n",
        "$$\n",
        "where $i\\in [0, batch\\_size), j\\in [0, vocab\\_size)$\n",
        "$$Loss = \\frac{1}{N}\\sum_{i}^{N}l_i$$\n",
        "\n",
        "Derivative: let's calculate $\\frac{\\delta l}{\\delta logits_j}$ and $\\frac{\\delta l}{\\delta logits_y}$, respectively. Let $s=logits$, for brievity.\n",
        "hence,\n",
        "$$l_i = -log\\dfrac{e^{s_{y_i}}}{\\sum_{j}e^{s_j}}\n",
        "$$\n",
        "## derivative\n",
        "see [my blog](https://romenlaw.blogspot.com/2024/06/study-notes-of-simple-neuro-network.html) for working:\n",
        "\n",
        "$$\\frac{\\delta l_i}{\\delta s_j} = P_i = softmax(s) \\\\\n",
        "\\frac{\\delta l_i}{\\delta s_y} = P_i-1 = softmax(s)-1 \\\\\n",
        "\\therefore \\frac{\\delta Loss}{\\delta s_j} = \\frac{1}{N}\\times P_i \\\\\n",
        "\\frac{\\delta Loss}{\\delta s_y} = \\frac{1}{N}\\times (P_i-1)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PblBFqmQGGUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fast = F.cross_entropy(logits, ys)\n",
        "print(loss_fast.item(), 'diff: ', (loss_fast - loss).item())"
      ],
      "metadata": {
        "id": "aCosFMbyGKyF",
        "outputId": "4a258aaf-c28d-45da-fa4b-9f389c05aa1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.5082900524139404 diff:  4.76837158203125e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dlogits = F.softmax(logits, dim=1)\n",
        "#dlogits[range(batch_size), ys] -= 1\n",
        "dlogits = F.softmax(logits, dim=1) - F.one_hot(ys, vocab_size)\n",
        "\n",
        "dlogits = dlogits / batch_size\n",
        "cmp('dlogits', dlogits, logits)"
      ],
      "metadata": {
        "id": "LrmDZ6k9sDhJ",
        "outputId": "8f7e7f63-8337-4c97-e491-0209322a9d1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlogits         | exact: False | approx: True  | maxdiff: 5.122274160385132e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.one_hot(ys, vocab_size)[0], ys"
      ],
      "metadata": {
        "id": "QNJVgD7Z75S5",
        "outputId": "549021b4-68b7-40bf-e3b3-3a6c83a35c0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0]),\n",
              " tensor([12, 14,  8, 21,  8, 14, 12,  5,  9,  7,  3,  4,  5, 11,  5, 12,  9, 15,\n",
              "         15, 12, 16,  1,  0,  9, 15,  0,  1,  9, 15, 20,  5, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs=F.softmax(logits, 1)\n",
        "probs[0], probs[0].sum(), probs[0].max()"
      ],
      "metadata": {
        "id": "ZrfCpRDPV1sJ",
        "outputId": "beabe989-8435-444f-ddc8-358ef5ea368a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0358, 0.0162, 0.0248, 0.0362, 0.0667, 0.0391, 0.0147, 0.1270, 0.0311,\n",
              "         0.0959, 0.0074, 0.0117, 0.0738, 0.0272, 0.0494, 0.0693, 0.0127, 0.0159,\n",
              "         0.0436, 0.0241, 0.0283, 0.0084, 0.0072, 0.0245, 0.0506, 0.0307, 0.0275],\n",
              "        grad_fn=<SelectBackward0>),\n",
              " tensor(1., grad_fn=<SumBackward0>),\n",
              " tensor(0.1270, grad_fn=<MaxBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(dlogits)[0]*batch_size, dlogits[0].sum()"
      ],
      "metadata": {
        "id": "AjXl1idgV9X6",
        "outputId": "ad0f5a49-5f79-4d51-a996-ddf4d1490ca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0358,  0.0162,  0.0248,  0.0362,  0.0667,  0.0391,  0.0147,  0.1270,\n",
              "          0.0311,  0.0959,  0.0074,  0.0117, -0.9262,  0.0272,  0.0494,  0.0693,\n",
              "          0.0127,  0.0159,  0.0436,  0.0241,  0.0283,  0.0084,  0.0072,  0.0245,\n",
              "          0.0506,  0.0307,  0.0275], grad_fn=<MulBackward0>),\n",
              " tensor(-1.3970e-09, grad_fn=<SumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))\n",
        "cx1 = ax1.imshow(dlogits.detach()*batch_size, cmap='gray')\n",
        "ax1.set_title('dlogits')\n",
        "fig.colorbar(cx1, ax=ax1)\n",
        "\n",
        "cx2 = ax2.imshow((probs).detach(), cmap='gray')\n",
        "ax2.set_title('probs')\n",
        "fig.colorbar(cx2, ax=ax2)"
      ],
      "metadata": {
        "id": "XXQL1em5VEKt",
        "outputId": "8c37978c-a4fe-4ca6-a016-0d5f6150a764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fac5b07a2f0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3 - Fast Batch Norm\n",
        "see [my blog](https://romenlaw.blogspot.com/2024/06/calculating-gradient-using-computation.html) for the analytical calculation.\n",
        "<p><img src='https://camo.githubusercontent.com/5caa8bf914be33124a2d303f6bfa1ac9479d73bddfac7115f4f80fe80a6bdb00/68747470733a2f2f6b686172736869742e6769746875622e696f2f696d672f62617463685f6e6f726d616c697a6174696f6e2e706e67'/>\n",
        "</p>\n",
        "\n",
        "mapping to our variable names: x is h_prebn, y is h_preact_fast\n",
        "\n",
        "find dh_prebn, given h_preact_fast\n",
        "\n",
        "##1 dL/dxi\n",
        "$$\\frac{\\delta L}{\\delta \\hat x_i}=\\frac{\\delta L}{\\delta y_i} \\times \\frac{\\delta y_i}{\\delta \\hat x_i} = \\frac{\\delta L}{\\delta y_i} \\times \\gamma\n",
        "$$\n",
        "##2 dL/dVar\n",
        "$\\sigma^2$ acts on every row of $\\hat x_i$ (which has 32 rows), so the back prop arrows into $\\sigma^2$ needs to be summed up for each row.\n",
        "$$\\frac{\\delta L}{\\delta \\sigma^2} = \\sum_i^N \\left(\\frac{\\delta L}{\\delta \\hat x_i} \\times \\frac{\\delta \\hat x_i}{\\delta \\sigma^2}\\right) \\\\\n",
        "= \\sum_i^N \\left[\\frac{\\delta L}{\\delta y_i} \\gamma (-\\frac{1}{2})(x_i-\\mu)(\\sigma^2+\\epsilon)^{-3/2}\\right] \\\\\n",
        "= -\\frac{1}{2}\\sum_i^N \\left[\\frac{\\delta L}{\\delta y_i} \\gamma (x_i-\\mu)(\\sigma^2+\\epsilon)^{-3/2}\\right]\n",
        "$$\n",
        "##3 dL/d\n",
        "There are two paths from L to : from $\\hat x_i$, and from $\\sigma^2$\n",
        "\n",
        "Similarly, $\\mu$ acts on every row of x, so the back prop arrows into $\\mu$ needs to be summed up for each row.\n",
        "\n",
        "$$\\frac{\\delta L}{\\delta \\mu} = \\sum_i^N\\left(\\frac{\\delta L}{\\delta \\hat x_i}\\times\\frac{\\delta \\hat x_i}{\\delta \\mu}\\right) + \\frac{\\delta L}{\\delta \\sigma^2}\\times\\frac{\\delta \\sigma^2}{\\delta \\mu}\n",
        "$$\n",
        "now,\n",
        "$$\\frac{\\delta \\hat x_i}{\\delta \\mu} = -(\\sigma^2+\\epsilon)^{-1/2}\n",
        "$$\n",
        "$$\\frac{\\delta \\sigma^2}{\\delta \\mu} = \\frac{1}{N-1}\\sum_i^N(2\\mu-2x_i)\\\\\n",
        "=\\frac{2}{N-1}\\sum_i^N(\\mu-x_i) \\\\\n",
        "=\\frac{2}{N-1} (\\sum_i^N \\mu - \\sum_i^N x_i) \\\\\n",
        "=\\frac{2}{N-1} \\times 0 = 0\n",
        "$$\n",
        "$$\\therefore \\frac{\\delta L}{\\delta \\mu} = \\sum_i^N\\left(\\frac{\\delta L}{\\delta \\hat x_i}\\times\\frac{\\delta \\hat x_i}{\\delta \\mu}\\right)+0\\\\\n",
        "=-\\sum_i^N \\left(\\frac{\\delta L}{\\delta y_i}\\gamma(\\sigma^2+\\epsilon)^{-1/2}\\right)\n",
        "$$\n",
        "##4 dL/dxi\n",
        "There are 3 paths to xi\n",
        "1. from $\\hat x_i$ - this is one per row (32 of them)\n",
        "2. from $\\sigma^2$\n",
        "3. from $\\mu$\n",
        "\n",
        "so we need to add them up:\n",
        "$$\n",
        "\\frac{\\delta L}{\\delta x_i} = \\frac{\\delta L}{\\delta \\hat x_i}\\frac{\\delta \\hat x_i}{\\delta x_i} + \\frac{\\delta L}{\\delta \\sigma^2}\\frac{\\delta \\sigma^2}{\\delta x_i} + \\frac{\\delta L}{\\delta \\mu}\\frac{\\delta \\mu}{\\delta x_i}\n",
        "$$\n",
        "Now, let's do the building blocks one by one:\n",
        "$$\\frac{\\delta \\hat x_i}{\\delta x_i} = \\frac{\\delta}{\\delta x_i}\\left( \\frac{x_i-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}\\right) = (\\sigma^2+\\epsilon)^{-1/2}\n",
        "$$\n",
        "$$\\frac{\\delta \\sigma^2}{\\delta x_i}=\\frac{\\delta}{\\delta x_i}\\left( \\frac{1}{N-1}\\sum_i^N(x_i-\\mu)^2\\right)=\\frac{2}{N-1}(x_i-\\mu), \\quad \\text{notice that unlike }\\frac{\\delta \\sigma^2}{\\delta \\mu},\\text{ this is not 0 because we are only doing it for one row of x (which has 32 rows).}\n",
        "$$\n",
        "$$\\frac{\\delta \\mu}{\\delta x_i}=\\frac{\\delta}{\\delta x_i}\\left(\\frac{1}{N}\\sum_i^N x_i \\right) = \\frac{1}{N}\\sum_i^N 1 = \\frac{1}{N}\n",
        "$$\n",
        "putting it together: notice the renaming of i into j for all the sums to distinguish it from the xi (i.e. j denotes the for loop for all rows in the mini batch).\n",
        "$$\\frac{\\delta L}{\\delta x_i}\n",
        "=\\frac{\\delta L}{\\delta y_i}\\gamma(\\sigma^2+\\epsilon)^{-1/2} \\\\\n",
        "-\\frac{1}{2}\\sum_j^N \\left[\\frac{\\delta L}{\\delta y_j} \\gamma (x_j-\\mu)(\\sigma^2+\\epsilon)^{-3/2}\\right]\\frac{2}{N-1}(x_i-\\mu) \\\\\n",
        "-\\frac{1}{N}\\sum_j^N \\left(\\frac{\\delta L}{\\delta y_j}\\gamma(\\sigma^2+\\epsilon)^{-1/2}\\right)\n",
        "$$\n",
        "Notice that $\\hat x_i = (x_i-\\mu)(\\sigma^2+\\epsilon)^{-\\frac{1}{2}}$, substitue into the 2nd term:\n",
        "$$\\frac{\\delta L}{\\delta x_i}\n",
        "=\\gamma(\\sigma^2+\\epsilon)^{-\\frac{1}{2}}\\frac{\\delta L}{\\delta y_i} \\\\\n",
        "-\\frac{(\\sigma^2+\\epsilon)^{-\\frac{1}{2}}}{N}\\sum_j^N \\left[\\frac{\\delta L}{\\delta y_j} \\gamma \\hat x_j\\right]\\frac{1}{N-1}\\hat x_i \\\\\n",
        "-(\\sigma^2+\\epsilon)^{-1/2}\\sum_j^N \\left(\\frac{\\delta L}{\\delta y_j}\\gamma\\right) \\\\\n",
        "=\\frac{\\gamma(\\sigma^2+\\epsilon)^{-1/2}}{N}\\left[N\\frac{\\delta L}{\\delta y_i}\n",
        "-\\frac{N}{N-1}\\hat x_i\\sum_j^N \\left(\\frac{\\delta L}{\\delta y_j} \\hat x_j\\right) - \\sum_j^N \\left(\\frac{\\delta L}{\\delta y_j}\\right)\n",
        "\\right]\n",
        "$$"
      ],
      "metadata": {
        "id": "idKanaxlELrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hpreact_fast = bn_gamma * (h_prebn - h_prebn.mean(0, keepdim=True)) / torch.sqrt(h_prebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bn_bias\n",
        "print('max diff:', (hpreact_fast - h_preact).abs().max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2Iw5RinF-lC",
        "outputId": "72d99146-9310-4353-bcd0-fe4fcb46417b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=batch_size\n",
        "dh_prebn = bn_gamma*bn_varinv/n*( n*dh_preact - n/(n-1)*x_hat*(dh_preact*x_hat).sum(0) - dh_preact.sum(0))\n",
        "cmp('dh_prebn', dh_prebn, h_prebn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq7Lh6-HGqKv",
        "outputId": "a8ef946e-6b4b-4e2a-f41b-7e5c1faa1824"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dh_prebn        | exact: False | approx: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4 - putting it together"
      ],
      "metadata": {
        "id": "OhmQFKhOBi7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP initialisation"
      ],
      "metadata": {
        "id": "pYMzOLUYCXT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 10\n",
        "hidden_dim = 200\n",
        "\n",
        "g = torch.Generator().manual_seed(20240827)\n",
        "C = torch.randn((vocab_size, embed_dim),  generator=g)\n",
        "\n",
        "# hidden layer\n",
        "fan_in = embed_dim*block_size # we concat multiple C's to feed into hidden layer\n",
        "W1 = torch.randn((fan_in, hidden_dim), generator=g) * (5/3 / fan_in**0.5)\n",
        "b1 = torch.randn(hidden_dim,           generator=g) * 0.1 # experiment\n",
        "# output layer\n",
        "W2 = torch.randn((hidden_dim, vocab_size), generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,               generator=g) * 0.1 # experiment with non-zero\n",
        "\n",
        "# batch normalisation 1D layer placed after hidden layer, hence dim=hidden_dim\n",
        "bn_gamma = torch.randn((1, hidden_dim),    generator=g) * 0.1 + 1.0\n",
        "bn_beta = torch.randn((1, hidden_dim),     generator=g) * 0.1\n",
        "bn_running_mean = torch.zeros((1, hidden_dim))\n",
        "bn_running_var = torch.ones((1, hidden_dim))\n",
        "\n",
        "# the above are initialised with non-standard values to magnify any incorrect values\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bn_gamma, bn_beta]\n",
        "print('total params: ', sum([p.nelement() for p in parameters]))\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "nz76GBtrCYn0",
        "outputId": "a5bc3a71-a548-4b31-d3c1-5c716c21972e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total params:  12297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training"
      ],
      "metadata": {
        "id": "URuEchvCDAfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "n = batch_size\n",
        "lossi = []\n",
        "with torch.no_grad():\n",
        "  for i in range(max_steps):\n",
        "\n",
        "    # construct mini-batch:\n",
        "    # generate a list of random indices, length of list if batch_size\n",
        "    ix = torch.randint(low=0, high=X_train.shape[0], size=(batch_size,), generator=g)\n",
        "    xs = X_train[ix]  # (batch_size, block_size)\n",
        "    ys = Y_train[ix]  # (batch_size)\n",
        "\n",
        "    ##################################\n",
        "    # forward pass (expanded version)\n",
        "    ##################################\n",
        "    # embedding ---------------------------\n",
        "    emb = C[xs] # (batch_size, block_size, hidden_dim)\n",
        "    embcat = emb.view(emb.shape[0], -1)\n",
        "\n",
        "    # hidden layer ------------------------\n",
        "    h_prebn = embcat @ W1 + b1 # (batch_size, hidden_dim)\n",
        "\n",
        "    # BN layer (expended version) ----------------------------\n",
        "    bn_mean = h_prebn.mean(dim=0, keepdim=True)\n",
        "    bn_var = h_prebn.var(dim=0, keepdim=True, unbiased=True)\n",
        "    bn_varinv = (bn_var + 1e-5)**-0.5  # 1/sqrt(var+eps)\n",
        "    x_hat = (h_prebn - bn_mean) * bn_varinv\n",
        "    h_preact = bn_gamma * x_hat + bn_beta\n",
        "    # with torch.no_grad():\n",
        "    #   bn_running_mean = 0.999 * bn_running_mean + 0.001 * bn_mean\n",
        "    #   bn_running_var = 0.999 * bn_running_var + 0.001 * bn_var\n",
        "\n",
        "    # Non-linearity ----------------------\n",
        "    h = torch.tanh(h_preact)  # (batch_size, hidden_dim)\n",
        "\n",
        "    # output layer -----------------------\n",
        "    logits = h @ W2 + b2 # (hidden_dim, vocab_size)\n",
        "    # loss function (extended version) ----------------------\n",
        "    loss = F.cross_entropy(logits, ys)\n",
        "\n",
        "    ################\n",
        "    # backward pass - using manual calculation instead of loss.backward()\n",
        "    ################\n",
        "    dC, dW1, db1, dW2, db2, dbn_gamma, dbn_beta = None, None, None, None, None, None, None\n",
        "\n",
        "    # since we used the cross_entropy function, need to used the fast grad from exercise 2\n",
        "    dlogits = F.softmax(logits, dim=1)\n",
        "    dlogits[range(n), ys] -= 1\n",
        "    dlogits /= n\n",
        "\n",
        "    dW2 = h.T @ dlogits\n",
        "    db2 = dlogits.sum(dim=0)\n",
        "    dh = dlogits @ W2.T\n",
        "\n",
        "    dh_preact = (1.0- h**2) * dh\n",
        "\n",
        "    dh_prebn = bn_gamma*bn_varinv/n*( n*dh_preact - n/(n-1)*x_hat*(dh_preact*x_hat).sum(0) - dh_preact.sum(0))\n",
        "    dbn_gamma = (dh_preact * x_hat).sum(0, keepdim=True)\n",
        "    dbn_beta = dh_preact.sum(0, keepdim=True)\n",
        "\n",
        "    dW1 = embcat.T @ dh_prebn\n",
        "    db1 = dh_prebn.sum(dim=0)\n",
        "    dembcat = dh_prebn @ W1.T\n",
        "\n",
        "    demb = dembcat.view(emb.shape)\n",
        "    dC = torch.einsum('abc,abg->cg', F.one_hot(xs, vocab_size).float(), demb)\n",
        "    # dC = torch.zeros_like(C)\n",
        "    # for k in range(xs.shape[0]):\n",
        "    #   for j in range(xs.shape[1]):\n",
        "    #     ix = xs[k,j]\n",
        "    #     dC[ix] += demb[k,j]\n",
        "\n",
        "    grads = [dC, dW1, db1, dW2, db2, dbn_gamma, dbn_beta]\n",
        "\n",
        "    ###############\n",
        "    # update\n",
        "    ###############\n",
        "    lr = 0.1 if i<100000 else 0.01\n",
        "    for p, grad in zip(parameters, grads):\n",
        "      #p.data += -lr * p.grad # using pyTorch grads\n",
        "      p.data += -lr * grad # using manually calculated grads\n",
        "\n",
        "    # tracking\n",
        "    lossi.append(loss)\n",
        "    if i%10000 == 0:\n",
        "      print('%6d/%7d %2.10f' % (i, max_steps, loss))\n",
        "\n",
        "    # if i>1000:\n",
        "    # break\n",
        "  print('%6d/%7d %2.10f' % (i, max_steps, loss))"
      ],
      "metadata": {
        "id": "uno3clNWCzFZ",
        "outputId": "32ec765a-5328-405d-ee52-6df95183022b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     0/ 200000 3.6914379597\n",
            " 10000/ 200000 1.9552644491\n",
            " 20000/ 200000 2.2685542107\n",
            " 30000/ 200000 1.9765737057\n",
            " 40000/ 200000 2.1635541916\n",
            " 50000/ 200000 2.3569927216\n",
            " 60000/ 200000 2.6716287136\n",
            " 70000/ 200000 2.3283567429\n",
            " 80000/ 200000 2.2069654465\n",
            " 90000/ 200000 2.1901471615\n",
            "100000/ 200000 2.0944044590\n",
            "110000/ 200000 2.1021707058\n",
            "120000/ 200000 1.9481284618\n",
            "130000/ 200000 2.1118209362\n",
            "140000/ 200000 2.0295965672\n",
            "150000/ 200000 1.7541403770\n",
            "160000/ 200000 1.9991391897\n",
            "170000/ 200000 1.9426642656\n",
            "180000/ 200000 2.0940511227\n",
            "190000/ 200000 2.2560067177\n",
            "199999/ 200000 2.0233426094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### for debugging\n",
        "\n",
        "# for t in [ logits, h, h_preact,\n",
        "#         x_hat, bn_varinv, bn_var, bn_diff2, bn_diff, bn_mean,\n",
        "#         bn_gamma, bn_beta,\n",
        "#         h_prebn, embcat, emb ]:\n",
        "#   t.retain_grad()\n",
        "# loss.backward()\n",
        "# cmp('dlogits', dlogits, logits)\n",
        "# cmp('dW2', dW2, W2)\n",
        "# cmp('db2', db2, b2)\n",
        "# cmp('dh', dh, h)\n",
        "# cmp('dh_preact', dh_preact, h_preact)\n",
        "# cmp('dh_prebn', dh_prebn, h_prebn)\n",
        "# cmp('dbn_gamma', dbn_gamma, bn_gamma)\n",
        "# cmp('dbn_beta',dbn_beta, bn_beta)\n",
        "# cmp('dW1', dW1, W1)\n",
        "# cmp('db1', db1, b1)\n",
        "# cmp('dembcat', dembcat, embcat)\n",
        "# cmp('demb', demb, emb)\n",
        "# cmp('dC', dC, C)"
      ],
      "metadata": {
        "id": "2wkGkxeWj2NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calibrate the batch norm at the end of training\n",
        "\n",
        "with torch.no_grad():\n",
        "  # pass the training set through\n",
        "  emb = C[X_train]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  # measure the mean/std over the entire training set\n",
        "  bnmean = hpreact.mean(0, keepdim=True)\n",
        "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
      ],
      "metadata": {
        "id": "PXp0Z6Bvpf0p"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## validate"
      ],
      "metadata": {
        "id": "BN317mbMP5vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def split_loss(split):\n",
        "  \"\"\"Returns the required split of the samples and labels\n",
        "  split - one of 'train', 'val', 'test'\n",
        "  \"\"\"\n",
        "  x,y={\n",
        "      'train': (X_train, Y_train),\n",
        "      'val': (X_dev, Y_dev),\n",
        "      'test': (X_test, Y_test)\n",
        "  }[split]\n",
        "  emb = C[x] # (N=Num of samples, block_size, emb_dim)\n",
        "  h_preact = emb.view(-1, embed_dim*block_size) @ W1 + b1\n",
        "  h_preact = bn_gamma * (h_preact - bnmean) * (bnvar + 1e-5)**-0.5 + bn_beta\n",
        "\n",
        "  h = torch.tanh( h_preact ) # (N, hidden_dim)\n",
        "\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "id": "SGLthbTLOuJK",
        "outputId": "0308b40c-421a-4b5b-fd81-80e4f4a4f746",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.0743484497070312\n",
            "val 2.1163837909698486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss is 2.07-2.11, comparable to the previous makemore notebook using various methods."
      ],
      "metadata": {
        "id": "qYdhR3JIg5iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(20240827+10) # diff seed from training\n",
        "\n",
        "for _ in range(20): # let's generate 20 samples\n",
        "  out=[]\n",
        "  context=[0]*block_size # start with '...'\n",
        "\n",
        "  while True:\n",
        "    emb = C[ torch.tensor([context]) ]  # embedding of the 3-letters (context)\n",
        "    h_preact = emb.view(emb.shape[0], -1) @ W1 + b1\n",
        "    h_preact = bn_gamma * (h_preact - bnmean) / (bnvar+1e-5)**0.5 + bn_beta\n",
        "\n",
        "    h = torch.tanh(h_preact)\n",
        "\n",
        "    logits = h @ W2 + b2\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "    context = context[1:]+[ix]  # shift the context by 1\n",
        "    out.append(ix)\n",
        "    if ix==0: # if generated a dot, then it's end of word\n",
        "      break\n",
        "  print (''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "id": "9O44GnCJgVeb",
        "outputId": "f6afd7b1-1871-4a94-b554-56210f37ff43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adi.\n",
            "jetti.\n",
            "izren.\n",
            "ise.\n",
            "maret.\n",
            "ken.\n",
            "eson.\n",
            "sevveros.\n",
            "shokybora.\n",
            "oriaman.\n",
            "eprick.\n",
            "briaha.\n",
            "chant.\n",
            "calionnaleiah.\n",
            "kyni.\n",
            "cobie.\n",
            "agrenabi.\n",
            "elyn.\n",
            "mani.\n",
            "katkalizoylin.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "makemore_backprop.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}